---
title: Paper accepted in Psychonomic Bulletin & Review!
date: 2025-09-30
share: true
profile: false
---

**When "train" turns into "terrain": can the perceived syllable rate be guided by linguistic information? Read all about it in our new paper: “Is rate-dependent perception affected by linguistic information about the intended syllable rate?”**

<!--more-->

## Published!

Our paper “Is rate-dependent perception affected by linguistic information about the intended syllable rate?”, authored by {{< mention "giulio-severijnen" >}}, {{< mention "admin" >}}, and James McQueen, was published in *Psychonomic Bulletin & Review*. You can find the full text and the accompanying data repository at the bottom of this post.

## What's it about?

Listeners are faced with the task of dealing with huge amounts of acoustic variability in speech. One of these types of variability stems from differences in speaking rate between talkers, which in turn strongly affects the duration of different speech sounds such as consonants (e.g., *beer* vs. *pier*), or vowels (Dutch *stad* vs. *staat*, ‘city’ vs. ‘state’). The task for the listener is to perceive the correct speech sounds despite those differences in speech rate, which listeners achieve through rate-dependent perception: perceiving speech relative to the rate in the surrounding context.

In this paper we examined **which types of information listeners use during rate-dependent perception**. More specifically, is it mostly driven by acoustic information (i.e., low-level, acoustics), or do listeners also make use of non-acoustic, linguistic information, such as tracking the number of syllables.

We tested this by having participants listen to different word lists that either had an acoustically different number of syllables (monosyllabic words or bisyllabic words), or lists that were acoustically identical but we imposed a different *intended* number of syllables through orthography. In these latter lists, the words were somewhere between monosyllabic and bisyllabic words: for example, a recording of [t?rɛin] is midway between (monosyllabic) *trein* "train" and (disyllabic) *terrein* "terrain". When we showed people words on a screen of what the speaker intended to say, **they indeed showed evidence of interpreting the ambiguous recordings as monosyllabic (if "trein" was on screen) or disyllabic (if "terrein" was on screen)**. However, another experiment showed that people did not use this linguistic information in rate-dependent perception.

<img src="https://media.springernature.com/full/springer-static/image/art%3A10.3758%2Fs13423-025-02746-x/MediaObjects/13423_2025_2746_Fig5_HTML.png" alt="Figure 5, Severijnen et al 2025" width="400"/>

## Why is this important?

This research further characterizes the exact sources of information that listeners do or do not use during speech perception. This is important for our understanding of how humans are so successful at understanding spoken language in everyday situations. In particular, it informs models of speech perception regarding the role of context: people can interpret the same recording differently depending on other sources of information, like a preceding sentence, world knowledge, or accompanying visual signals we see. This study shows that 'not all context is created equal': some information (here: linguistic information about the intended number of syllables) is used for some processes, but not others.

## Full reference

The full citation, open access PDF, and all data are publicly available from the links below:

> {{< cite page="/publication/severijnen-etal-2025-pbr" view="4" >}}
