---
title: 'Beat gestures made by human-like avatars affect speech perception'
authors:
  - matteo-maran
  - Renske RÃ¶tjes
  - Anna R. E. Schreurs
  - admin
date: '2025-01-01T00:00:00Z'
author_notes:
  - ''
  - 'Equal contribution'
  - 'Equal contribution'
doi: '10.21437/Interspeech.2025-178'

# Schedule page publish date (NOT publication's date).
publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['1']

# Publication name and optional abbreviated publication name.
publication: 'In *Proceedings of Interspeech 2025*, 5038-5042, doi:[10.21437/Interspeech.2025-178](https://doi.org/10.21437/Interspeech.2025-178)'
publication_short: ''

abstract: 'In face-to-face communication, several visual cues support speech perception. Even the timing of simple up-and-down flicks of the hand, called beat gestures, can convey word stress, changing what individuals hear (e.g., CONtent vs. conTENT). While beat gestures have been traditionally investigated in human-to-human communications, nowadays individuals increasingly interact with computer-controlled avatars (e.g., virtual assistants). The present study tested whether beat gestures produced by an avatar affect word stress perception, similarly to human gestures. Furthermore, this study tested whether a minimal visual cue such as a 2D moving disc can also affect speech perception. Beat gestures made by the avatar significantly affected speech perception, albeit slightly less than human-made gestures. The disc condition did not affect speech perception. The present work lays the foundation for the application of (beat) gesturing avatars, which could be used to boost speech intelligibility.'

# # Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags:
  - beat gesture
  - lexical stress
  - audiovisual integration
  - gesture-speech integration
  - prosody

featured: false

# links:
# - name: ""
#   url: ""
url_pdf: 'https://www.isca-archive.org/interspeech_2025/maran25_interspeech.pdf'
url_code: ''
url_dataset: 'https://doi.org/10.34973/3k98-1q60'
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# # Featured image
# # To use, add an image named `featured.jpg/png` to your page's folder.
# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
#   focal_point: ''
#   preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<!-- {{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). -->
