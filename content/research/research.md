---
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://wowchemy.com/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.

widget: blank # See https://wowchemy.com/docs/page-builder/
headless: true # This file represents a page section.
weight: 30 # Order that this section will appear.
title: 'Our research'
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '2'
  # Add custom styles
  css_style:
  css_class:
---

> How is it possible that we can easily have a conversation with someone even if that someone is shouting over several other talkers, speaks in busy street noise, wears a face mask, talks very fast, has a strange accent, or produces uhm’s all the time?

## Vision

The human brain is uniquely equipped to successfully perceive the speech of those around us – even in quite challenging listening environments. At the SPEAC research group, we investigate the psychological and neurobiological mechanisms that underlie the exceptional human behavior of spoken communication. We specifically focus on how humans integrate input from multiple modalities, including such visual cues as lip movements, facial expressions, and hand gestures.

## The big questions

The work we do contributes to a better understanding of how multimodal spoken communication can usually take place so smoothly. For instance, how do seemingly meaningless up-and-down hand movements, known as *beat gestures*, influence what words we hear? How do listeners manage to understand talkers in challenging listening conditions, such as in loud background noise or when there are competing talkers around? How do listeners ‘tune in’ to a particular talker with his or her own peculiar pronunciation habits? What is the role of context (i.e., acoustic, semantic, and situational context) in speech processing? Finally, we also develop methodological tools to facilitate research in the speech sciences.

## How do we conduct our research?

The kinds of behavioral experiments we run include (i) playing participants artificially manipulated videos with a speech categorization task (what's this word?); (ii) speech-in-noise intelligibility experiments (what’s this sentence?); (iii) various psycholinguistic paradigms such as repetition priming (e.g., lexical decision). We use eye-tracking to study the time-course of speech processing on a millisecond timescale (e.g., visual world paradigm). We also apply neuroimaging techniques (EEG, MEG, tACS) to uncover the neurobiological mechanisms involved in the temporal decoding of speech, with a particular focus on oscillatory dynamics.

## Wanna know more?

[Check out some of our demos](/demos/), showcasing the kinds of experiments we run...
