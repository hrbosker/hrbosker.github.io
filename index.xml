<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SPEAC | Hans Rutger Bosker</title>
    <link>https://hrbosker.github.io/</link>
      <atom:link href="https://hrbosker.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>SPEAC | Hans Rutger Bosker</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 07 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hrbosker.github.io/media/logo_hu4ee931c5040e3d0fbcac8149a377b250_283935_300x300_fit_lanczos_3.png</url>
      <title>SPEAC | Hans Rutger Bosker</title>
      <link>https://hrbosker.github.io/</link>
    </image>
    
    <item>
      <title>Manual McGurk effect</title>
      <link>https://hrbosker.github.io/demos/manual-mcgurk/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/manual-mcgurk/</guid>
      <description>&lt;h2 id=&#34;do-you-hear-voornaam-or-voornaam&#34;&gt;Do you hear &lt;em&gt;VOORnaam&lt;/em&gt; or &lt;em&gt;voorNAAM&lt;/em&gt;?&lt;/h2&gt;
&lt;p&gt;In the video below, you&amp;rsquo;ll see a talker produce a Dutch word. Is he saying &lt;em&gt;VOORnaam&lt;/em&gt; (Eng. &amp;ldquo;first name&amp;rdquo;, with stress on the first syllable &lt;em&gt;VOOR-&lt;/em&gt;) or &lt;em&gt;voorNAAM&lt;/em&gt; (Eng. &amp;ldquo;respectable&amp;rdquo;, with stress on the second syllable &lt;em&gt;-NAAM&lt;/em&gt;). In other words: &lt;strong&gt;where do you hear the stress?&lt;/strong&gt;&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/manual-mcgurk/voornaam_AV_swbeat_sw_4.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;blockquote&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Spoiler: click here to reveal the video specs&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Audio:&lt;/strong&gt; &lt;em&gt;ambiguous&lt;/em&gt;; midway between &lt;em&gt;VOORnaam&lt;/em&gt; &amp;ndash; &lt;em&gt;voorNAAM&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lips:&lt;/strong&gt; head taken from a recording of &lt;em&gt;VOORnaam&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hands:&lt;/strong&gt; beat gesture aligned to the &lt;strong&gt;first&lt;/strong&gt; syllable&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now play the video below. &lt;strong&gt;Where do you hear the stress now?&lt;/strong&gt;&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/manual-mcgurk/voornaam_AV_wsbeat_sw_4.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;blockquote&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Spoiler: click here to reveal the video specs&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Audio:&lt;/strong&gt; &lt;em&gt;ambiguous&lt;/em&gt;; midway between &lt;em&gt;VOORnaam&lt;/em&gt; &amp;ndash; &lt;em&gt;voorNAAM&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lips:&lt;/strong&gt; head taken from a recording of &lt;em&gt;VOORnaam&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hands:&lt;/strong&gt; beat gesture aligned to the &lt;strong&gt;second&lt;/strong&gt; syllable&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;explanation&#34;&gt;Explanation&lt;/h2&gt;
&lt;p&gt;The audio in these videos is perfectly identical: it has been manipulated to be ambiguous, falling roughly midway between &lt;em&gt;VOORnaam&lt;/em&gt; and &lt;em&gt;voorNAAM&lt;/em&gt;. The head of the talker is also the same: it has been copy-pasted from a video recording of the talker saying &lt;em&gt;VOORnaam&lt;/em&gt;. &lt;strong&gt;The only difference between these two videos is the timing of the hand gesture.&lt;/strong&gt; In the first clip, the talker produces a beat gesture on the &lt;em&gt;first&lt;/em&gt; syllable, while in the second video the talker gestures on the &lt;em&gt;second&lt;/em&gt; syllable. Our experiments show that this slight change in timing has major consequences for perception. When we ask a group of Dutch participants to indicate what word they hear the talker say, the majority reports hearing &lt;em&gt;VOORnaam&lt;/em&gt; in the first clip, but &lt;em&gt;voorNAAM&lt;/em&gt; in the second clip.&lt;/p&gt;
&lt;h2 id=&#34;how-hands-help-us-hear&#34;&gt;How hands help us hear&lt;/h2&gt;
&lt;p&gt;When we have a face-to-face conversation, we don&amp;rsquo;t only exchange sounds. We also move our head, hands, and body to the rhythm of the speech. &lt;em&gt;Beat gestures&lt;/em&gt; are relatively &amp;lsquo;simple&amp;rsquo; up-and-down hand gestures that are closely aligned to the rhythm of speech. They tend to fall on the stressed syllable in free-stress languages, such as English and Dutch. These videos demonstrate that people are sensitive to the timing of beat gestures, influencing lexical stress perception. In &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2021-procroysocb&#34;&gt;Bosker &amp;amp; Peeters (2021)&lt;/a&gt;, this effect was termed the &lt;strong&gt;manual McGurk effect&lt;/strong&gt;. That is, just like seeing a talker close their lips can make you hear the sound /b/ in the classic McGurk effect (&lt;a href=&#34;https://www.nature.com/articles/264746a0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;McGurk &amp;amp; McDonald, 1976&lt;/a&gt;), so can the timing of hand gestures influence speech perception in the manual McGurk effect.&lt;/p&gt;
&lt;h2 id=&#34;why-is-this-important&#34;&gt;Why is this important?&lt;/h2&gt;
&lt;p&gt;The manual McGurk effect is the first demonstration of how the timing of hand gestures influences low-level speech perception. Even the simplest flicks-of-the-hands that do not convey any particular meaning of themselves can shape what words you hear. This promises that these seemingly unimportant hand gestures contribute meaningfully to audiovisual speech intelligibility. Perhaps &amp;rsquo;enriching&amp;rsquo; our speech with carefully timed gestures can help our audience understand our spoken message, particularly in challenging listening conditions, such as in noise.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/david-peeters/&#34;&gt;David Peeters&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2021-procroysocb/&#34;&gt;Beat gestures influence which speech sounds you hear&lt;/a&gt;.
  &lt;em&gt;Proceedings of the Royal Society B: Biological Sciences, 288&lt;/em&gt;, 20202419, doi:10.1098/rspb.2020.2419.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3243428_3/component/file_3280864/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2021-procroysocb/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/b7kue/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1098/rspb.2020.2419&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/ronny-bujok/&#34;&gt;Ronny Bujok&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/antje-s.-meyer/&#34;&gt;Antje S. Meyer&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2022).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bujok-etal-2022-sp/&#34;&gt;Visible lexical stress cues on the face do not influence audiovisual speech perception&lt;/a&gt;.
  In &lt;em&gt;Proceedings of Speech Prosody 2022&lt;/em&gt; (ed. S. Frota, M. Cruz, and M. Vig√°rio), 259-263, doi:10.21437/SpeechProsody.2022-53.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3387404_1/component/file_3387405/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bujok-etal-2022-sp/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/um7ph&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.21437/SpeechProsody.2022-53&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Ronny Bujok, Antje S. Meyer, and Hans Rutger Bosker (2022). Audiovisual perception of lexical stress: Beat gestures are stronger visual cues for lexical stress than visible articulatory cues on the face. &lt;em&gt;PsyArXiv Preprints&lt;/em&gt;, doi:&lt;a href=&#34;https://doi.org/10.31234/osf.io/y9jck&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.31234/osf.io/y9jck&lt;/a&gt;, data:&lt;a href=&#34;https://osf.io/4d9w5/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://osf.io/4d9w5/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>First how-to</title>
      <link>https://hrbosker.github.io/resources/how-to/howto1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/howto1/</guid>
      <description>&lt;p&gt;This is the subtitle.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;praatcode = 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Some disclaimer&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Save all</title>
      <link>https://hrbosker.github.io/resources/scripts/save-all/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/scripts/save-all/</guid>
      <description>&lt;p&gt;Praat can only save one object at a time for you. If you have multiple objects in your object window you&amp;rsquo;d like to save in one go, you can use this script. It can either save objects by their object name or by their id number.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can also &lt;a href=&#34;../save-all.praat&#34;&gt;download the script&lt;/a&gt; as a .praat file.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;################################################################################
### Hans Rutger Bosker, Radboud University
### HansRutger.Bosker@ru.nl
### Date: 23 June 2022, run in Praat 6.2.12 on Windows 10
### License: CC BY-NC 4.0
################################################################################

	###&amp;gt;&amp;gt; This script saves all selected objects to the directory &amp;#39;dir_out$&amp;#39;
	###&amp;gt;&amp;gt;	with either:
	###&amp;gt;&amp;gt;   - their object name (e.g., &amp;#34;sentence1.wav&amp;#34;)
	###&amp;gt;&amp;gt;			&amp;gt; set variable &amp;#39;save_method$&amp;#39; to &amp;#34;name&amp;#34; [default]
	###&amp;gt;&amp;gt;   - their id number in the Praat object window (e.g., &amp;#34;42.wav&amp;#34;)
	###&amp;gt;&amp;gt;			&amp;gt; set variable &amp;#39;save_method$&amp;#39; to &amp;#34;id&amp;#34;
	###&amp;gt;&amp;gt;
	###&amp;gt;&amp;gt; Sounds are saved as .wav files,
	###&amp;gt;&amp;gt; other object types (TextGrids, Spectrum, etc.) are saved
	###&amp;gt;&amp;gt; with their own extension type (.TextGrid, .Spectrum).
	###&amp;gt;&amp;gt;
	###&amp;gt;&amp;gt; Default: the script will overwrite pre-existing files.
	###&amp;gt;&amp;gt; Set variable &amp;#39;overwrite$&amp;#39; to &amp;#34;no&amp;#34; if you want Praat
	###&amp;gt;&amp;gt; to throw an error instead.



################################################################################
### Variables you will definitely need to customize:
################################################################################

### Where should the selected objects be saved?

dir_out$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;

### Should Praat overwrite pre-existing files?

overwrite$ = &amp;#34;yes&amp;#34;
#overwrite$ = &amp;#34;no&amp;#34;

### Do you want to save each object by its object name or by its id number?
### If object name, then use &amp;#34;name&amp;#34; (e.g., &amp;#34;sentence1.wav&amp;#34;).
### If object id number, then use &amp;#34;id&amp;#34; (e.g., &amp;#34;42.wav&amp;#34;).

save_method$ = &amp;#34;name&amp;#34;
#save_method$ = &amp;#34;id&amp;#34;





################################################################################
### Before we start, let&amp;#39;s check whether you&amp;#39;ve entered sensible
### input for the variables above...
################################################################################

### Let&amp;#39;s check if the output directory exists.
### This script will throw an error if the directory doesn&amp;#39;t exist
### (i.e., it won&amp;#39;t write to a mysterious temp directory).

### First check whether the input directory ends in a backslash (if so, removed)

if right$(dir_out$,1)=&amp;#34;/&amp;#34;
	dir_out$ = left$(dir_out$,length(dir_out$)-1)
elsif right$(dir_out$,1)=&amp;#34;\&amp;#34;
	dir_out$ = left$(dir_out$,length(dir_out$)-1)
endif

### Then create a temporary txt file in the folder
### and try to write it to the output folder.

### NOTE: The &amp;#34;nocheck&amp;#34; below asks Praat not to complain if the folder
### does *not* exist. We&amp;#39;ll manually check whether the saving of this
### temp txt file has succeeded or not further down below.

temp_filename$ = dir_out$ + &amp;#34;/&amp;#34; + &amp;#34;my_temporary_Praat_file.txt&amp;#34;
nocheck writeFileLine: temp_filename$, &amp;#34;This is just to check if the directory exists&amp;#34;

### Can the file be found?

file_exists_yesno = fileReadable(temp_filename$)

if file_exists_yesno = 1
	# if you *could* read that temp txt file,
	# this confirms that the directory is valid.
	# Then you can delete it.
	deleteFile: temp_filename$
else
	# if that file wasn&amp;#39;t readable, that means that the directory wasn&amp;#39;t valid. 
	printline The folder &amp;#39;dir_out$&amp;#39; was not found
	exit Your directory doesn&amp;#39;t exist. Check spelling. The directory must *already* exist.
endif





################################################################################
################################################################################
#################################    SCRIPT    #################################
################################################################################
################################################################################

### Make sure you&amp;#39;ve selected the objects you&amp;#39;d like to save in
### the Praat object window. If nothing is selected, the script exits.

nSelected = numberOfSelected()
if nSelected = 0
	exit No objects selected.
endif

### Store the object id numbers in an array

for thisObject to nSelected
	objectArray [&amp;#39;thisObject&amp;#39;] = selected(&amp;#39;thisObject&amp;#39;)
endfor

### Loop through this array and for each id number
### select the corresponding object and save it.

for thisArrayNumber to nSelected
	objectId = objectArray [&amp;#39;thisArrayNumber&amp;#39;]
	select &amp;#39;objectId&amp;#39;
	type$ = extractWord$(selected$(), &amp;#34;&amp;#34;)
	name$ = extractLine$(selected$(), &amp;#34; &amp;#34;)
	
	if save_method$ = &amp;#34;name&amp;#34;
		if type$ = &amp;#34;Sound&amp;#34;
			does_file_exist = fileReadable(&amp;#34;&amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.wav&amp;#34;)
			if does_file_exist = 1
				if overwrite$ = &amp;#34;no&amp;#34;
					exit The file &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.wav&amp;#39; already exists! If you wish to overwrite, set the variable overwrite$ to &amp;#34;yes&amp;#34;.
				endif
			endif
			Write to WAV file... &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.wav
		else
			does_file_exist = fileReadable(&amp;#34;&amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.&amp;#39;type$&amp;#39;&amp;#34;)
			if does_file_exist = 1
				if overwrite$ = &amp;#34;no&amp;#34;
					exit The file &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.&amp;#39;type$&amp;#39; already exists! If you wish to overwrite, set the variable overwrite$ to &amp;#34;yes&amp;#34;.
				endif
			endif
			Write to text file... &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;.&amp;#39;type$&amp;#39;
		endif
	elsif save_method$ = &amp;#34;id&amp;#34;
		if type$ = &amp;#34;Sound&amp;#34;
			does_file_exist = fileReadable(&amp;#34;&amp;#39;dir_out$&amp;#39;\&amp;#39;objectId$&amp;#39;.wav&amp;#34;)
			if does_file_exist = 1
				if overwrite$ = &amp;#34;no&amp;#34;
					exit The file &amp;#39;dir_out$&amp;#39;\&amp;#39;objectId$&amp;#39;.wav&amp;#39; already exists! If you wish to overwrite, set the variable overwrite$ to &amp;#34;yes&amp;#34;.
				endif
			endif
			Write to WAV file... &amp;#39;dir_out$&amp;#39;\&amp;#39;objectId&amp;#39;.wav
		else
			does_file_exist = fileReadable(&amp;#34;&amp;#39;dir_out$&amp;#39;\&amp;#39;objectId$&amp;#39;.&amp;#39;type$&amp;#39;&amp;#34;)
			if does_file_exist = 1
				if overwrite$ = &amp;#34;no&amp;#34;
					exit The file &amp;#39;dir_out$&amp;#39;\&amp;#39;objectId$&amp;#39;.&amp;#39;type$&amp;#39; already exists! If you wish to overwrite, set the variable overwrite$ to &amp;#34;yes&amp;#34;.
				endif
			endif
			Write to text file... &amp;#39;dir_out$&amp;#39;\&amp;#39;objectId&amp;#39;.&amp;#39;type$&amp;#39;
		endif
	endif
endfor

### Now set the selection back to what it was before running this script.

for current to nSelected
	objectId = objectArray [&amp;#39;current&amp;#39;]
	if current = 1
		select &amp;#39;objectId&amp;#39;
	else
		plus &amp;#39;objectId&amp;#39;
	endif
endfor

################################################################################
# End of script
################################################################################
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Laurel or Yanny?</title>
      <link>https://hrbosker.github.io/demos/laurel-yanny/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/laurel-yanny/</guid>
      <description>&lt;h2 id=&#34;same-audio-different-perception&#34;&gt;Same audio, different perception&lt;/h2&gt;
&lt;p&gt;In May 2018, social media exploded after the surfacing of &lt;a href=&#34;https://twitter.com/CloeCouture/status/996218489831473152&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an audio clip&lt;/a&gt; that some perceived as &lt;em&gt;Laurel&lt;/em&gt;, but others as &lt;em&gt;Yanny&lt;/em&gt;. &lt;strong&gt;Listen and decide for yourself:&lt;/strong&gt;&lt;/p&gt;






  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S7.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;p&gt;#Laurelgate was quickly seen as the auditory version of &lt;a href=&#34;https://en.wikipedia.org/wiki/The_dress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#TheDress&lt;/a&gt;, a photo going viral in 2015 of a white and gold dress, or was it black and blue? But how fixed is this divide between individuals? &lt;strong&gt;Can we turn #Yannists into #Laurelites, and vice versa?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;higher-vs-lower-frequencies&#34;&gt;Higher vs. lower frequencies&lt;/h2&gt;
&lt;p&gt;Acoustic analysis of the original clip suggests that the higher frequencies (&amp;gt;1000 Hz) resembled the word &lt;em&gt;Yanny&lt;/em&gt;, but the lower frequencies (&amp;lt;1000 Hz) are more like &lt;em&gt;Laurel&lt;/em&gt;. This can be seen in the figure at the top of this page, where the upper part of the middle panel (&lt;em&gt;Original&lt;/em&gt;) is more like the right panel (&lt;em&gt;Yanny&lt;/em&gt;), but the lower part is more like the left panel (&lt;em&gt;Laurel&lt;/em&gt;). This is best demonstrated by artificially emphasizing/attenuating the higher vs. lower frequencies in the audio clip.&lt;/p&gt;
&lt;p&gt;In these sounds, we gradually attenuate (&lt;em&gt;~turn down&lt;/em&gt;) the higher frequencies while we simultaneously emphasize (&lt;em&gt;~turn up&lt;/em&gt;) the lower frequencies. &lt;strong&gt;Play the sounds below, can you hear &lt;em&gt;Laurel&lt;/em&gt; turning into &lt;em&gt;Yanny&lt;/em&gt;?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;





  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S4.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S5.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S6.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S7.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S8.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S9.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/Audio%20S10.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Click here for audio specs&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Middle clip:&lt;/strong&gt; original Laurel/Yanny clip&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manipulation:&lt;/strong&gt; filtered by 10 bandpass filters (with center frequencies: 31.5, 63, 125, 250, 500, 1000, 2000, 4000, 8000, 16000 Hz; using a Hann window with a roll-off width of 20, 20, 40, 80, 100, 100, 100, 100, 100, 100 Hz, respectively). Opposite intensity manipulation for high (&amp;gt;1000 Hz) vs. low (&amp;lt;1000 Hz) frequency bands in steps of 6 dB.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top clip:&lt;/strong&gt; -18 dB attenuation for higher frequency bands, +18 dB emphasis for lower frequency bands.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bottom clip:&lt;/strong&gt; +18 dB emphasis for higher frequency bands, -18 dB attenuation for lower frequency bands.&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;p&gt;OK, so we can guide what people hear by artificially editing the higher vs. lower frequencies in the clip. &lt;strong&gt;But can we also make someone hear one and the same clip differently?&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;lets-add-laurels-telephone-number&#34;&gt;Let&amp;rsquo;s add Laurel&amp;rsquo;s telephone number&lt;/h2&gt;
&lt;p&gt;The perception of speech sounds is influenced by the surrounding acoustic context. The same sound can be perceived differently when, for instance, the acoustics of a preceding sentence are changed. Below, you will hear the original Laurel/Yanny clip, but this time preceded by a telephone number: 496-0356. In the first clip, we filtered out (&lt;em&gt;~removed&lt;/em&gt;) the lower frequencies in the telephone number leaving only the high frequency content. In the second clip, we filtered out the higher frequencies leaving only the low frequency content. Note: the Laurel/Yanny clip itself is identical in the two audios. &lt;strong&gt;Do you hear a different name after each telephone number?&lt;/strong&gt;&lt;/p&gt;






  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/hi_ambig.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;







  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/demos/laurel-yanny/lo_ambig.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;

&lt;h2 id=&#34;numbing-your-ears&#34;&gt;Numbing your ears&lt;/h2&gt;
&lt;p&gt;In a crowd-sourced experiment with &amp;gt;500 online participants, we found that the same people were more likely to report hearing &lt;em&gt;Laurel&lt;/em&gt; for the first clip, but &lt;em&gt;Yanny&lt;/em&gt; for the second clip. This is because the high-frequency content in the telephone number in the first clip &lt;em&gt;&amp;rsquo;numbs your ears&amp;rsquo;&lt;/em&gt; for any following high-frequency content, thus making the lower frequencies stand out more, biasing towards perception &lt;em&gt;Laurel&lt;/em&gt;. And vice versa, the low-frequency content in the telephone number in the second clip &lt;em&gt;&amp;rsquo;numbs your ears&amp;rsquo;&lt;/em&gt; for any following low-frequency content, thus making the higher frequencies stand out more, biasing perception towards &lt;em&gt;Yanny&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-11&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Click here for the results of the experiment&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;This is Figure 1 from &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-2018-jasa&#34;&gt;Bosker (2018, &lt;em&gt;JASA&lt;/em&gt;)&lt;/a&gt; showing people&amp;rsquo;s responses in panel C. The blue line shows the proportion of &lt;em&gt;Yanny&lt;/em&gt; responses after a high-pass filtered telephone number (~first clip above), which is higher than the red line illustrating people&amp;rsquo;s responses for the &lt;strong&gt;same Laurel/Yanny clips&lt;/strong&gt; after a low-pass filtered telephone number (~second clip above).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://asa.scitation.org/na101/home/literatum/publisher/aip/journals/content/jas/2018/jas.2018.144.issue-6/1.5070144/20181206/images/large/1.5070144.figures.online.f2.jpeg
&#34; alt=&#34;Figure 1, Bosker 2018 JASA&#34; width=&#34;800&#34;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;why-is-this-important&#34;&gt;Why is this important?&lt;/h2&gt;
&lt;p&gt;These social media phenomena are great examples of how &lt;em&gt;our perception of the world is strongly context-dependent&lt;/em&gt;. What we perceive is &lt;strong&gt;not&lt;/strong&gt; wholly determined by the input signal alone, but also by the context in which the signal is perceived, including sounds heard previously, our expectations, who is talking, etc. As such, they highlight the subtle intricacies of human perception.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-2018-jasa/&#34;&gt;Putting Laurel and Yanny in context&lt;/a&gt;.
  &lt;em&gt;The Journal of the Acoustic Society of America, 144&lt;/em&gt;(6), EL503-EL508, doi:10.1121/1.5070144.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3005418_7/component/file_3012156/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-2018-jasa/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/63wdh/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1121/1.5070144&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Annotate</title>
      <link>https://hrbosker.github.io/resources/scripts/annotate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/scripts/annotate/</guid>
      <description>&lt;p&gt;This script streamlines an annotation workflow: it presents a TextGrid for manual annotation to the user, you perform some changes, and when you click Next, it automatically saves the changes and presents the next TextGrid, and so on. This is particularly useful for when you have forced aligned TextGrids (e.g., from &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;WebMAUS&lt;/a&gt; or &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;EasyAlign&lt;/a&gt;) that you&amp;rsquo;d like to manually evaluate and edit.&lt;/p&gt;
&lt;p&gt;Moreover, the script keeps track of who annotated what, can continue where you left off yesterday, allows users to enter comments about their annotations, and blinds file names to avoid human annotation biases. The script can be updated to present new empty TextGrids (instead of any pre-existing ones, in case you only have .wav files) or to automatically perform changes to TextGrid tiers/intervals before presenting them for manual annotation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can also &lt;a href=&#34;../annotate.praat&#34;&gt;download the script&lt;/a&gt; as a .praat file.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;################################################################################
### Hans Rutger Bosker, Radboud University
### HansRutger.Bosker@ru.nl
### Date: 30 June 2022, run in Praat 6.2.12 on Windows 10
### License: CC BY-NC 4.0
################################################################################

	###&amp;gt;&amp;gt; This script reads a directory containing sound files with pre-existing TextGrids,
	###&amp;gt;&amp;gt;	for instance resulting from a forced aligner (e.g., WebMAUS or EasyAlign).
	###&amp;gt;&amp;gt;	IMPORTANT: Every Sound should have a pre-existing TextGrid file **with the same name**!
	###&amp;gt;&amp;gt;	It opens every Sound + Textgrid combination, presents it to the user for editing,
	###&amp;gt;&amp;gt;	allows the user to enter comments about the annotations, and then saves the
	###&amp;gt;&amp;gt;	edited TextGrid with &amp;#34;_edited&amp;#34; suffix in the subfolder &amp;#39;edited_textgrids&amp;#39;.
	###&amp;gt;&amp;gt;	User comments are tracked in the file &amp;#39;annotation_log.txt&amp;#39; in the same subfolder.
	###&amp;gt;&amp;gt;	
	###&amp;gt;&amp;gt;	&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; If you **do not** yet have pre-existing TextGrids (i.e., only sound files),	&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
	###&amp;gt;&amp;gt;	&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; you can adjust the script to read all .wav files, create new empty TextGrids,	&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
	###&amp;gt;&amp;gt;	&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; and present those for editing and saving...									&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
	###&amp;gt;&amp;gt;	&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; See the line with &amp;#34;CREATE EMPTY TEXTGRIDS&amp;#34;									&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
	###&amp;gt;&amp;gt;
	###&amp;gt;&amp;gt; This script can be run by multiple users simultaneously, for instance when
	###&amp;gt;&amp;gt;   multiple annotators are working on the same shared folder. It keeps track
	###&amp;gt;&amp;gt;   of what files have already been edited: it only presents TextGrids for editing
	###&amp;gt;&amp;gt;   that do not yet have an &amp;#34;_edited&amp;#34; version pre-existing in the subfolder.
	###&amp;gt;&amp;gt;   This also means that users can close the script or Praat at anytime
	###&amp;gt;&amp;gt;   without losing data. Then, next time someone runs the script, it will
	###&amp;gt;&amp;gt;   start with the files that are &amp;#39;left over&amp;#39; from the previous run.
	###&amp;gt;&amp;gt;	NOTE: This checking of which files already exist can slow the script down
	###&amp;gt;&amp;gt;	when working with folders with &amp;gt;5000 files...
	###&amp;gt;&amp;gt;
	###&amp;gt;&amp;gt; At present, the script **only** presents pre-existing tiers and intervals
	###&amp;gt;&amp;gt;   for editing (e.g., adding boundaries, dragging boundaries around, etc.).
	###&amp;gt;&amp;gt;   This script can be augmented by automatically adding tiers or intervals
	###&amp;gt;&amp;gt;   before the TextGrid is presented for editing, so users can annotate
	###&amp;gt;&amp;gt;   new tiers/intervals. See the line with &amp;#34;ADD/REMOVE TIERS HERE&amp;#34;.

################################################################################
### Variables you will definitely need to customize:
################################################################################

### Where can the Sound and TextGrid files be found?

dir_in$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;

### Do you want to use &amp;#39;blinded&amp;#39; objects in Praat to avoid human biases in annotation?
### Default value: &amp;#34;yes&amp;#34;
### Change to &amp;#34;no&amp;#34; if you want to use original object names.

blinded$ = &amp;#34;yes&amp;#34;





################################################################################
### Before we start, let&amp;#39;s check whether you&amp;#39;ve entered sensible
### input for the variables above...
################################################################################

### Let&amp;#39;s check if the input directory exists.
### This script will throw an error if the directory doesn&amp;#39;t exist
### (i.e., it won&amp;#39;t write to a mysterious temp directory).

### First check whether the input directory ends in a backslash (if so, removed)

if right$(dir_in$,1)=&amp;#34;/&amp;#34;
	dir_in$ = left$(dir_in$,length(dir_in$)-1)
elsif right$(dir_in$,1)=&amp;#34;\&amp;#34;
	dir_in$ = left$(dir_in$,length(dir_in$)-1)
endif

### Then create a temporary txt file in the folder
### and try to write it to the input folder.

### NOTE: The &amp;#34;nocheck&amp;#34; below asks Praat not to complain if the folder
### does *not* exist. We&amp;#39;ll manually check whether the saving of this
### temp txt file has succeeded or not further down below.

temp_filename$ = dir_in$ + &amp;#34;/&amp;#34; + &amp;#34;my_temporary_Praat_file.txt&amp;#34;
nocheck writeFileLine: temp_filename$, &amp;#34;This is just to check if the directory exists&amp;#34;

### Can the file be found?

file_exists_yesno = fileReadable(temp_filename$)

if file_exists_yesno = 1
	# if you *could* read that temp txt file,
	# this confirms that the directory is valid.
	# Then you can delete it.
	deleteFile: temp_filename$
else
	# if that file wasn&amp;#39;t readable, that means that the directory wasn&amp;#39;t valid. 
	printline The folder &amp;#39;dir_in$&amp;#39; was not found
	exit Your directory doesn&amp;#39;t exist. Check spelling. The directory must *already* exist.
endif

## Let&amp;#39;s also check whether a subfolder with edited TextGrids already exists,
## for instance when the script has been run and exited before.

temp_filename$ = dir_in$ + &amp;#34;/edited_textgrids/&amp;#34; + &amp;#34;my_temporary_Praat_file.txt&amp;#34;
nocheck writeFileLine: temp_filename$, &amp;#34;This is just to check if the subfolder exists&amp;#34;

### Can the file be found?

subfolderfile_exists_yesno = fileReadable(temp_filename$)

if subfolderfile_exists_yesno = 1
	# if you *could* read that temp txt file,
	# this confirms that the subfolder already exists.
	# Then you can delete it.
	deleteFile: temp_filename$
else
	# if it didn&amp;#39;t yet exist, let&amp;#39;s create the subfolder
	createFolder: &amp;#34;&amp;#39;dir_in$&amp;#39;/edited_textgrids&amp;#34;
endif





################################################################################
################################################################################
#################################    SCRIPT    #################################
################################################################################
################################################################################

## Let&amp;#39;s keep track of who annotated which file. This can be helpful when
## multiple annotators run the same script on the same shared folder.

beginPause: &amp;#34;Please enter your name:&amp;#34;
	text: &amp;#34;annotator&amp;#34;, &amp;#34;&amp;#34;
clicked = endPause: &amp;#34;Next&amp;#34;, 1

## Now we create a list of TextGrid files in the input directory:

Create Strings as file list: &amp;#34;list_of_files&amp;#34;, &amp;#34;&amp;#39;dir_in$&amp;#39;/*.TextGrid&amp;#34;

	#######################################################################################
	## CREATE EMPTY TEXTGRIDS
	########################
	## If you do not yet have pre-existing TextGrids (but a folder with only sound files instead),
	## you can read the sound files in the directory and create empty TextGrids for the user
	## to edit.
	## Adjust this script as follows:
	## - Change *.TextGrid to *.wav in the line above.
	## - Change *.TextGrid to *.wav in the line below starting with &amp;#34;extposition$&amp;#34;
	## - Replace this line: Read from file... &amp;#39;dir_in$&amp;#39;\&amp;#39;name$&amp;#39;.TextGrid
	##		with this line: To TextGrid: &amp;#34;manual&amp;#34;, &amp;#34;&amp;#34;
	#######################################################################################

nfiles = Get number of strings
if nfiles = 0
	exit The directory &amp;#39;dir_in$&amp;#39; does not contain any TextGrid files.
endif

## By randomizing this file list, it allows for multiple users to simultanously work
## on the same folder without overwriting previous annotations. It also reduces the risk
## of human biases in annotations (e.g., annotator fatigue affecting one condition more
## than another condition).

Randomize

## Now we&amp;#39;ll loop through the list and present individual files...

for i from 1 to &amp;#39;nfiles&amp;#39;
	select Strings list_of_files
	
	fileplusext$ = Get string... &amp;#39;i&amp;#39;
	extposition = index(fileplusext$, &amp;#34;.TextGrid&amp;#34;)
	name$ = left$(fileplusext$, (&amp;#39;extposition&amp;#39;-1))

	outname$ = &amp;#34;&amp;#39;name$&amp;#39;_edited&amp;#34;
	fulloutname$ = &amp;#34;&amp;#39;dir_in$&amp;#39;/edited_textgrids/&amp;#39;outname$&amp;#39;.TextGrid&amp;#34;

	## Let&amp;#39;s check if an &amp;#34;_edited&amp;#34; version already exists.
	## The script only presents those files for editing that do not yet have been edited before.
	
	editedfile_exists_yesno = fileReadable(fulloutname$)
	if editedfile_exists_yesno
		do_nothing = 1
	else
		Read from file... &amp;#39;dir_in$&amp;#39;\&amp;#39;name$&amp;#39;.wav
		if blinded$ = &amp;#34;yes&amp;#34;
			Rename... current_Sound
		endif
		sound_name$ = selected$(&amp;#34;Sound&amp;#34;)
		## If a filename contains spaces, Praat replaces these spaces with underscores.
		## Example: &amp;#34;file number 1.wav&amp;#34; in a given folder becomes
		##			&amp;#34;file_number_1.wav&amp;#34; in the Praat object window.
		## Therefore, it is important **not** to use a filename variable (here: &amp;#39;name$&amp;#39;)
		## in &amp;#39;selecting commands&amp;#39; in Praat, like &amp;#39;select&amp;#39; and &amp;#39;plus&amp;#39;!
		## Better still: do not use spaces in filenames!
		
		Read from file... &amp;#39;dir_in$&amp;#39;\&amp;#39;name$&amp;#39;.TextGrid
		if blinded$ = &amp;#34;yes&amp;#34;
			Rename... current_TextGrid
		endif
		tg_name$ = selected$(&amp;#34;TextGrid&amp;#34;)

		#######################################################################################
		## ADD/REMOVE TIERS HERE
		########################
		## This is where we you could adjust the script to automatically add/remove tiers
		## and/or automatically adjust intervals (setting them to the nearest zero crossings?).
		## Duplicating tiers can be helpful when you want to view original vs. manually edited
		## tiers below/above each other in one and the same edited TextGrid.
		## Example:
		## &amp;gt; Duplicate tier... 1 1 newtier
		## [ARGUMENTS: position_of_tier_to_duplicate position_for_new_tier name_of_new_tier]
		#######################################################################################

		plus Sound &amp;#39;sound_name$&amp;#39;
		Edit

		beginPause: &amp;#34;Please check and edit this TextGrid.&amp;#34;
			comment: &amp;#34;Please check and edit the annotations.&amp;#34;
			text: &amp;#34;Comments&amp;#34;, &amp;#34;&amp;#34;
		clicked = endPause: &amp;#34;Next&amp;#34;, 1
		
		editor TextGrid &amp;#39;tg_name$&amp;#39;
			Close
		endeditor

		select TextGrid &amp;#39;tg_name$&amp;#39;
		Write to text file... &amp;#39;fulloutname$&amp;#39;
		plus Sound &amp;#39;sound_name$&amp;#39;
		Remove

		appendFileLine: &amp;#34;&amp;#39;dir_in$&amp;#39;/edited_textgrids/annotation_log.txt&amp;#34;, annotator$, tab$, name$, tab$, comments$
	endif
endfor

select Strings list_of_files
Remove

################################################################################
# End of script
################################################################################
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Second how-to</title>
      <link>https://hrbosker.github.io/resources/how-to/howto2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/howto2/</guid>
      <description>&lt;p&gt;This is the subtitle.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;firstobject = 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Some disclaimer&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Repackaging speech</title>
      <link>https://hrbosker.github.io/demos/repackaging/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/repackaging/</guid>
      <description>&lt;h2 id=&#34;title&#34;&gt;Title&lt;/h2&gt;
&lt;p&gt;Text.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/oded-ghitza/&#34;&gt;Oded Ghitza&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2018-lcn/&#34;&gt;Entrained theta oscillations guide perception of subsequent speech: Behavioral evidence from rate normalization&lt;/a&gt;.
  &lt;em&gt;Language, Cognition and Neuroscience,33&lt;/em&gt;(8), 955-967, doi:10.1080/23273798.2018.1439179.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_2538752_11/component/file_2630351/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2018-lcn/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1080/23273798.2018.1439179&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Batch processing</title>
      <link>https://hrbosker.github.io/resources/scripts/batch-processing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/scripts/batch-processing/</guid>
      <description>&lt;p&gt;This script is an in-house template / starting point for batch processing multiple files. Adapt it to your own needs to apply a particular function to multiple files or multiple time intervals within each file.&lt;/p&gt;
&lt;p&gt;In its current form, the script reads each .wav file &lt;em&gt;plus&lt;/em&gt; accompanying TextGrid in a given input directory, extracts all non-empty intervals individually, and then loops over those to find the ones labelled &amp;ldquo;vowel&amp;rdquo;. It then allows the user to apply a particular function to those intervals (such as &lt;code&gt;Scale intensity: 65&lt;/code&gt;), after which it concatenates the individual intervals back together, and saves the output in an output directory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; In its current form, the script does not run any function on its input. It really only serves as a starting point, including snippets of code we regularly use and now do not need to look up every time we want to do batch processing in Praat.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You can also &lt;a href=&#34;../batch-processing.praat&#34;&gt;download the script&lt;/a&gt; as a .praat file.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;################################################################################
### Hans Rutger Bosker, Radboud University
### HansRutger.Bosker@ru.nl
### Date: 6 July 2022, run in Praat 6.2.12 on Windows 10
### License: CC BY-NC 4.0
################################################################################


	###&amp;gt;&amp;gt; This script is a starting point for batch processing a set of files.
	###&amp;gt;&amp;gt;	The script basically reads files in an input directory and runs a
	###&amp;gt;&amp;gt;	a to-be-defined function [see &amp;#39;Perform your function here&amp;#39; below]
	###&amp;gt;&amp;gt;	and writes the output to an output directory . This saves me having
	###&amp;gt;&amp;gt;	to look up how to create a file list, how to loop over files, etc.
	###&amp;gt;&amp;gt;	
	###&amp;gt;&amp;gt; Since this was basically intended for in-house use, I&amp;#39;ve added in bits
	###&amp;gt;&amp;gt;	and pieces that I find useful to have ready-to-go, such as:
	###&amp;gt;&amp;gt;	&amp;#39;beginPause&amp;#39; for manually specifying variables.

################################################################################
### Variables you will definitely need to customize:
################################################################################

### Where can the files be found?

dir_in$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;

### Where should the output files be saved?

dir_out$ = &amp;#34;C:\Users\hanbos\mysounds\output&amp;#34;





################################################################################
### Let&amp;#39;s check whether the directories specified above exist...
################################################################################

### Let&amp;#39;s check if the input directory exists.
### This script will throw an error if the directory doesn&amp;#39;t exist
### (i.e., it won&amp;#39;t write to a mysterious temp directory).

### First check whether the input directory ends in a backslash (if so, removed)

if right$(dir_in$,1)=&amp;#34;/&amp;#34;
	dir_in$ = left$(dir_in$,length(dir_in$)-1)
elsif right$(dir_in$,1)=&amp;#34;\&amp;#34;
	dir_in$ = left$(dir_in$,length(dir_in$)-1)
endif

### Then create a temporary txt file in the folder
### and try to write it to the input folder.

### NOTE: The &amp;#34;nocheck&amp;#34; below asks Praat not to complain if the folder
### does *not* exist. We&amp;#39;ll manually check whether the saving of this
### temp txt file has succeeded or not further down below.

temp_filename$ = dir_in$ + &amp;#34;/&amp;#34; + &amp;#34;my_temporary_Praat_file.txt&amp;#34;
nocheck writeFileLine: temp_filename$, &amp;#34;This is just to check if the directory exists&amp;#34;

### Can the file be found?

file_exists_yesno = fileReadable(temp_filename$)

if file_exists_yesno = 1
	# if you *could* read that temp txt file,
	# this confirms that the directory is valid.
	# Then you can delete it.
	deleteFile: temp_filename$
else
	# if that file wasn&amp;#39;t readable, that means that the directory wasn&amp;#39;t valid. 
	printline The folder &amp;#39;dir_in$&amp;#39; was not found
	exit Your input directory doesn&amp;#39;t exist. Check spelling. The directory must *already* exist.
endif

## Now re-do this for the output directory:

if right$(dir_out$,1)=&amp;#34;/&amp;#34;
	dir_out$ = left$(dir_out$,length(dir_out$)-1)
elsif right$(dir_out$,1)=&amp;#34;\&amp;#34;
	dir_out$ = left$(dir_out$,length(dir_out$)-1)
endif

### Then create a temporary txt file in the folder
### and try to write it to the input folder.

### NOTE: The &amp;#34;nocheck&amp;#34; below asks Praat not to complain if the folder
### does *not* exist. We&amp;#39;ll manually check whether the saving of this
### temp txt file has succeeded or not further down below.

temp_filename$ = dir_out$ + &amp;#34;/&amp;#34; + &amp;#34;my_temporary_Praat_file.txt&amp;#34;
nocheck writeFileLine: temp_filename$, &amp;#34;This is just to check if the directory exists&amp;#34;

### Can the file be found?

file_exists_yesno = fileReadable(temp_filename$)

if file_exists_yesno = 1
	# if you *could* read that temp txt file,
	# this confirms that the directory is valid.
	# Then you can delete it.
	deleteFile: temp_filename$
else
	# if that file wasn&amp;#39;t readable, that means that the directory wasn&amp;#39;t valid. 
	printline The folder &amp;#39;dir_out$&amp;#39; was not found
	exit Your output directory doesn&amp;#39;t exist. Check spelling. The directory must *already* exist.
endif





###########################################################################
##	FORM TO MANUALLY SPECIFY VARIABLES
###########################################################################
#beginPause: &amp;#34;Enter settings&amp;#34;
#	comment: &amp;#34;Provide instructions here&amp;#34;
#	real: &amp;#34;minPitch&amp;#34;, 70
#	real: &amp;#34;maxPitch&amp;#34;, 250
#	choice: &amp;#34;method&amp;#34;, 1
#	   option: &amp;#34;Flip F0 contour&amp;#34;
#	   option: &amp;#34;Expand/Contract F0 contour&amp;#34;
#	   option: &amp;#34;Flatten F0 contour&amp;#34;
#clicked = endPause (&amp;#34;Cancel&amp;#34;, &amp;#34;OK&amp;#34;, 2)
###########################################################################
###########################################################################





## Let&amp;#39;s create a list of all the files in the input directory.

Create Strings as file list: &amp;#34;list_of_files&amp;#34;, &amp;#34;&amp;#39;dir_in$&amp;#39;/*.wav&amp;#34;

nfiles = Get number of strings
if nfiles = 0
	exit The directory &amp;#39;dir_in$&amp;#39; does not contain any .wav files.
endif

## Now we&amp;#39;ll loop through the list...

for i from 1 to &amp;#39;nfiles&amp;#39;
	select Strings list_of_files
	
	fileplusext$ = Get string... &amp;#39;i&amp;#39;
	extposition = index(fileplusext$, &amp;#34;.wav&amp;#34;)
	name$ = left$(fileplusext$, (&amp;#39;extposition&amp;#39;-1))

	Read from file... &amp;#39;dir_in$&amp;#39;\&amp;#39;name$&amp;#39;.wav
	Read from file... &amp;#39;dir_in$&amp;#39;\&amp;#39;name$&amp;#39;.TextGrid
	plus Sound &amp;#39;name$&amp;#39;
	Extract non-empty intervals... 1 no
	
	nSelected = numberOfSelected()

	## Assign an object number to each object (e.g., 1-5),
	## and save the id numbers of each object to an array.

	for thisObject to nSelected
		objectArray [&amp;#39;thisObject&amp;#39;] = selected(&amp;#39;thisObject&amp;#39;)
	endfor

	for j to nSelected
		curr_objectId = objectArray [&amp;#39;j&amp;#39;]
		select &amp;#39;curr_objectId&amp;#39;
		curr_objectName$ = selected$(&amp;#34;Sound&amp;#34;)
		
		if curr_objectName$ = &amp;#34;vowel&amp;#34;

			########################################################################
			# Perform your function here!
			#	Example: Scale intensity... 65
			########################################################################

		endif
	endfor

	for j from 1 to nSelected
		curr_objectId = objectArray [&amp;#39;j&amp;#39;]
		if j = 1
			select &amp;#39;curr_objectId&amp;#39;
		else
			plus &amp;#39;curr_objectId&amp;#39;
		endif
	endfor
	Concatenate recoverably

	select Sound chain
	Write to WAV file... &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;_manipulated.wav
	select TextGrid chain
	Write to text file... &amp;#39;dir_out$&amp;#39;\&amp;#39;name$&amp;#39;_manipulated.TextGrid

	## Cleaning up...
	for j from 1 to nSelected
		curr_objectId = objectArray [&amp;#39;j&amp;#39;]
		if j = 1
			select &amp;#39;curr_objectId&amp;#39;
		else
			plus &amp;#39;curr_objectId&amp;#39;
		endif
	endfor
	plus Sound chain
	plus TextGrid chain
	plus Sound &amp;#39;name$&amp;#39;
	plus TextGrid &amp;#39;name$&amp;#39;
	Remove

endfor

select Strings list_of_files
Remove

################################################################################
# End of script
################################################################################
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Third how-to</title>
      <link>https://hrbosker.github.io/resources/how-to/howto3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/howto3/</guid>
      <description>&lt;p&gt;This is the subtitle.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;firstobject = 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Some disclaimer&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lombard speech</title>
      <link>https://hrbosker.github.io/demos/lombard-speech/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/lombard-speech/</guid>
      <description>&lt;h2 id=&#34;title&#34;&gt;Title&lt;/h2&gt;
&lt;p&gt;Text.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/martin-cooke/&#34;&gt;Martin Cooke&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2018-jasa/&#34;&gt;Talkers produce more pronounced amplitude modulations when speaking in noise&lt;/a&gt;.
  &lt;em&gt;The Journal of the Acoustical Society of America, 143&lt;/em&gt;(2), EL121-EL126, doi:10.1121/1.5024404.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_2537243_6/component/file_2554157/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2018-jasa/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1121/1.5024404&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/martin-cooke/&#34;&gt;Martin Cooke&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2020-jasa/&#34;&gt;Enhanced amplitude modulations contribute to the Lombard intelligibility benefit: Evidence from the Nijmegen Corpus of Lombard Speech&lt;/a&gt;.
  &lt;em&gt;The Journal of the Acoustical Society of America, 147&lt;/em&gt;(2), 721-730, doi:10.1121/10.0000646.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3186181_3/component/file_3186182/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2020-jasa/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://hdl.handle.net/1839/21ee5744-b5dc-4eed-9693-c37e871cdaf6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1121/10.0000646&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Cocktail party listening</title>
      <link>https://hrbosker.github.io/demos/cocktail-party/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/cocktail-party/</guid>
      <description>&lt;h2 id=&#34;title&#34;&gt;Title&lt;/h2&gt;
&lt;p&gt;Text.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/matthias-j.-sjerps/&#34;&gt;Matthias J. Sjerps&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/eva-reinisch/&#34;&gt;Eva Reinisch&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2020).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2020-scirep/&#34;&gt;Temporal contrast effects in human speech perception are immune to selective attention&lt;/a&gt;.
  &lt;em&gt;Scientific Reports, 10&lt;/em&gt;, 5607, doi:10.1038/s41598-020-62613-8.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3214645_6/component/file_3251038/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2020-scirep/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/dp7ck/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1038/s41598-020-62613-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Look and listen</title>
      <link>https://hrbosker.github.io/demos/visual-world-paradigm/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/visual-world-paradigm/</guid>
      <description>&lt;h2 id=&#34;title&#34;&gt;Title&lt;/h2&gt;
&lt;p&gt;Text.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/esperanza-badaya/&#34;&gt;Esperanza Badaya&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/martin-corley/&#34;&gt;Martin Corley&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2021).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2021-discproc/&#34;&gt;Discourse markers activate their, like, cohort competitors&lt;/a&gt;.
  &lt;em&gt;Discourse Processes, 58&lt;/em&gt;(9), 837-851, doi:10.1080/0163853X.2021.1924000.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3316633_4/component/file_3356284/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2021-discproc/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/rmj4e/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1080/0163853X.2021.1924000&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/marjolein-van-os/&#34;&gt;Marjolein van Os,&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/rik-does/&#34;&gt;Rik Does&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/geertje-van-bergen/&#34;&gt;Geertje van Bergen&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2019).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2019-jml/&#34;&gt;Counting ‚Äòuhm‚Äôs: how tracking the distribution of native and non-native disfluencies influences online language comprehension&lt;/a&gt;.
  &lt;em&gt;Journal of Memory and Language, 106&lt;/em&gt;, 189-202, doi:10.1016/j.jml.2019.02.006.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_3029110_7/component/file_3038833/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2019-jml/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;



  
  
    
  
&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://osf.io/5y2e6/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  Dataset
&lt;/a&gt;











&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jml.2019.02.006&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/geertje-van-bergen/&#34;&gt;Geertje van Bergen&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2018).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2018-jml/&#34;&gt;Linguistic expectation management in online discourse processing: An investigation of Dutch inderdaad ‚Äòindeed‚Äô and eigenlijk ‚Äòactually‚Äô&lt;/a&gt;.
  &lt;em&gt;Journal of Memory and Language, 103&lt;/em&gt;, 191-209, doi:10.1016/j.jml.2018.08.004.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_2640593_2/component/file_2640592/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2018-jml/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jml.2018.08.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hugo-quene/&#34;&gt;Hugo Quen√©&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/ted-sanders/&#34;&gt;Ted Sanders&lt;/a&gt;&lt;/span&gt;, &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/nivja-h.-de-jong/&#34;&gt;Nivja H. de Jong&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2014).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-etal-2014-jml/&#34;&gt;Native ‚Äòum‚Äôs elicit prediction of low-frequency referents, but non-native ‚Äòum‚Äôs do not&lt;/a&gt;.
  &lt;em&gt;Journal of Memory and Language, 75&lt;/em&gt;, 104-116, doi:10.1016/j.jml.2014.05.004.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_1900237_6/component/file_2034223/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-etal-2014-jml/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1016/j.jml.2014.05.004&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Your own speech changes your ears</title>
      <link>https://hrbosker.github.io/demos/self/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/demos/self/</guid>
      <description>&lt;h2 id=&#34;title&#34;&gt;Title&lt;/h2&gt;
&lt;p&gt;Text.&lt;/p&gt;
&lt;h2 id=&#34;background-reading&#34;&gt;Background reading&lt;/h2&gt;
&lt;blockquote&gt;










  


&lt;div class=&#34;pub-list-item view-citation&#34; style=&#34;margin-bottom: 1rem&#34;&gt;
  &lt;i class=&#34;far fa-file-alt pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;

  
  

  &lt;span class=&#34;article-metadata li-cite-author&#34;&gt;
    

  &lt;span &gt;
      &lt;a href=&#34;https://hrbosker.github.io/author/hans-rutger-bosker/&#34;&gt;Hans Rutger Bosker&lt;/a&gt;&lt;/span&gt;
  &lt;/span&gt;
  (2017).
  &lt;a href=&#34;https://hrbosker.github.io/publication/bosker-2017-jeplmc/&#34;&gt;How our own speech rate influences our perception of others&lt;/a&gt;.
  &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, and Cognition, 43&lt;/em&gt;(8), 1225-1238, doi:10.1037/xlm0000381.
  
  &lt;p&gt;








  
    
  



&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://pure.mpg.de/rest/items/item_2364495_7/component/file_2472957/content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  PDF
&lt;/a&gt;



&lt;a href=&#34;#&#34; class=&#34;btn btn-outline-primary btn-page-header btn-sm js-cite-modal&#34;
        data-filename=&#34;/publication/bosker-2017-jeplmc/cite.bib&#34;&gt;
  Cite
&lt;/a&gt;













&lt;a class=&#34;btn btn-outline-primary btn-page-header btn-sm&#34; href=&#34;https://doi.org/10.1037/xlm0000381&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;
  DOI
&lt;/a&gt;


&lt;/p&gt;

  
  
&lt;/div&gt;



&lt;/blockquote&gt;
&lt;blockquote&gt;











&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Acoustic correlates of Dutch lexical stress re-examined: Spectral tilt is not always more reliable than intensity</title>
      <link>https://hrbosker.github.io/publication/severijnen-etal-2022-speechprosody/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/severijnen-etal-2022-speechprosody/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Evidence for selective adaptation and recalibration in the perception of lexical stress</title>
      <link>https://hrbosker.github.io/publication/bosker-2022-ls/index/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2022-ls/index/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Visible lexical stress cues on the face do not influence audiovisual speech perception</title>
      <link>https://hrbosker.github.io/publication/bujok-etal-2022-sp/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bujok-etal-2022-sp/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>A tool for efficient and accurate segmentation of speech data: Announcing POnSS</title>
      <link>https://hrbosker.github.io/publication/rodd-etal-2021-brm/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/rodd-etal-2021-brm/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Beat gestures influence which speech sounds you hear</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2021-procroysocb/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2021-procroysocb/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Discourse markers activate their, like, cohort competitors</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2021-discproc/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2021-discproc/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Listeners track talker-specific prosody to deal with talker-variability</title>
      <link>https://hrbosker.github.io/publication/severijnen-etal-2021-brainres/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/severijnen-etal-2021-brainres/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>The contribution of amplitude modulations in speech to perceived charisma</title>
      <link>https://hrbosker.github.io/publication/bosker-2021-bookchapter/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2021-bookchapter/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Using fuzzy string matching for automated assessment of listener transcripts in speech intelligibility studies</title>
      <link>https://hrbosker.github.io/publication/bosker-2021-brm/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2021-brm/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Biasing the perception of spoken words with transcranial alternating current stimulation</title>
      <link>https://hrbosker.github.io/publication/kosem-etal-2020-jcn/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/kosem-etal-2020-jcn/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Contextual speech rate influences morphosyntactic prediction and integration</title>
      <link>https://hrbosker.github.io/publication/kaufeld-etal-2020-lcn/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/kaufeld-etal-2020-lcn/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Control of speaking rate is achieved by switching between qualitatively distinct cognitive ‚Äògaits‚Äô: Evidence from simulation</title>
      <link>https://hrbosker.github.io/publication/rodd-etal-2020-psychreview/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/rodd-etal-2020-psychreview/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Enhanced amplitude modulations contribute to the Lombard intelligibility benefit: Evidence from the Nijmegen Corpus of Lombard Speech</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2020-jasa/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2020-jasa/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Eye-tracking the time course of distal and global speech rate effects</title>
      <link>https://hrbosker.github.io/publication/maslowski-etal-2020-jephpp/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/maslowski-etal-2020-jephpp/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Fluency in dialogue: Turn‚Äêtaking behavior shapes perceived fluency in native and nonnative speech</title>
      <link>https://hrbosker.github.io/publication/vanos-etal-2020-ll/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/vanos-etal-2020-ll/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>How visual cues to speech rate influence speech perception</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2020-qjep/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2020-qjep/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Knowledge-based and signal-based cues are weighted flexibly during spoken language comprehension</title>
      <link>https://hrbosker.github.io/publication/kaufeld-etal-2020-jeplmc/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/kaufeld-etal-2020-jeplmc/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Linguistic structure and meaning organize neural oscillations into a content-specific hierarchy</title>
      <link>https://hrbosker.github.io/publication/kaufeld-etal-2020-jneuro/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/kaufeld-etal-2020-jneuro/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Spectral contrast effects are modulated by selective attention in ‚Äòcocktail party‚Äô settings</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2020-app/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2020-app/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Temporal contrast effects in human speech perception are immune to selective attention</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2020-scirep/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2020-scirep/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Counting ‚Äòuhm‚Äôs: how tracking the distribution of native and non-native disfluencies influences online language comprehension</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2019-jml/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2019-jml/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Deriving the onset and offset times of planning units from acoustic and articulatory measurements</title>
      <link>https://hrbosker.github.io/publication/rodd-etal-2019-jasa/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/rodd-etal-2019-jasa/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>How the tracking of habitual rate influences speech perception</title>
      <link>https://hrbosker.github.io/publication/maslowski-etal-2019-jeplmc/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/maslowski-etal-2019-jeplmc/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Listeners normalize speech for contextual speech rate even without an explicit recognition task</title>
      <link>https://hrbosker.github.io/publication/maslowski-etal-2019-jasa/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/maslowski-etal-2019-jasa/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Entrained theta oscillations guide perception of subsequent speech: Behavioral evidence from rate normalization</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2018-lcn/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2018-lcn/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Linguistic expectation management in online discourse processing: An investigation of Dutch inderdaad ‚Äòindeed‚Äô and eigenlijk ‚Äòactually‚Äô</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2018-jml/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2018-jml/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Listening to yourself is special: Evidence from global speech rate tracking</title>
      <link>https://hrbosker.github.io/publication/maslowski-etal-2018-plosone/index/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/maslowski-etal-2018-plosone/index/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Neural entrainment determines the words we hear</title>
      <link>https://hrbosker.github.io/publication/kosem-etal-2018-currbiol/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/kosem-etal-2018-currbiol/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Putting Laurel and Yanny in context</title>
      <link>https://hrbosker.github.io/publication/bosker-2018-jasa/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2018-jasa/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;</description>
    </item>
    
    <item>
      <title>Talkers produce more pronounced amplitude modulations when speaking in noise</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2018-jasa/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2018-jasa/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Accounting for rate-dependent category boundary shifts in speech perception</title>
      <link>https://hrbosker.github.io/publication/bosker-2017-app/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2017-app/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>An entrained rhythm‚Äôs frequency, not phase, influences temporal sampling of speech</title>
      <link>https://hrbosker.github.io/publication/bosker-kosem-2017-interspeech/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-kosem-2017-interspeech/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Cognitive load makes speech sound fast, but does not modulate acoustic context effects</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2017-jml/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2017-jml/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT --&gt;
</description>
    </item>
    
    <item>
      <title>Foreign languages sound fast: evidence from implicit rate normalization</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2017-frontiers/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2017-frontiers/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>How our own speech rate influences our perception of others</title>
      <link>https://hrbosker.github.io/publication/bosker-2017-jeplmc/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2017-jeplmc/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>The role of temporal amplitude modulations in the political arena: Hillary Clinton vs. Donald Trump</title>
      <link>https://hrbosker.github.io/publication/bosker-2017-interspeech/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2017-interspeech/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Whether long-term tracking of speech rate affects perception depends on who is talking</title>
      <link>https://hrbosker.github.io/publication/maslowski-etal-2017-interspeech/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/maslowski-etal-2017-interspeech/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Listening under cognitive load makes speech sound fast</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2016-spire/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2016-spire/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Our own speech rate influences speech perception</title>
      <link>https://hrbosker.github.io/publication/bosker-2016-sp/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2016-sp/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Both native and non-native disfluencies trigger listeners‚Äô attention</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2015/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2015/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Normalization for speechrate in native and nonnative speech</title>
      <link>https://hrbosker.github.io/publication/bosker-reinisch-2015/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-reinisch-2015/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Native ‚Äòum‚Äôs elicit prediction of low-frequency referents, but non-native ‚Äòum‚Äôs do not</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2014-jml/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2014-jml/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Native speakers‚Äô perceptions of fluency and accent in L2 speech</title>
      <link>https://hrbosker.github.io/publication/pinget-etal-2014-lt/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/pinget-etal-2014-lt/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Perceptual adaptation to segmental and syllabic reductions in continuous spoken Dutch</title>
      <link>https://hrbosker.github.io/publication/poellmann-etal-2014-jphon/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/poellmann-etal-2014-jphon/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>The perception of fluency in native and nonnative speech</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2014-ll/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2014-ll/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT









&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>The processing and evaluation of fluency in native and non-native speech</title>
      <link>https://hrbosker.github.io/publication/bosker-2014-thesis/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2014-thesis/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Choosing a threshold for silent pauses to measure second language fluency</title>
      <link>https://hrbosker.github.io/publication/dejong-bosker-2013/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/dejong-bosker-2013/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Juncture (prosodic)</title>
      <link>https://hrbosker.github.io/publication/bosker-2013-ehll-juncture/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2013-ehll-juncture/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Sibilant consonants</title>
      <link>https://hrbosker.github.io/publication/bosker-2013-ehll-sibilants/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-2013-ehll-sibilants/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>What makes speech sound fluent? The contributions of pauses, speed and repairs</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2013-lt/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2013-lt/</guid>
      <description>&lt;!-- THIS MARKDOWN BIT IS CURRENTLY COMMENTED OUT
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/).
--&gt;
</description>
    </item>
    
    <item>
      <title>Whispered speech as input for cochlear implants</title>
      <link>https://hrbosker.github.io/publication/bosker-etal-2010/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/publication/bosker-etal-2010/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hrbosker.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://hrbosker.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://hrbosker.github.io/empty/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/empty/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://hrbosker.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://hrbosker.github.io/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/research/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
