<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>How to&#39;s | SPEAC | Hans Rutger Bosker</title>
    <link>https://hrbosker.github.io/resources/how-to/</link>
      <atom:link href="https://hrbosker.github.io/resources/how-to/index.xml" rel="self" type="application/rss+xml" />
    <description>How to&#39;s</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 07 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://hrbosker.github.io/resources/how-to/featured.jpg</url>
      <title>How to&#39;s</title>
      <link>https://hrbosker.github.io/resources/how-to/</link>
    </image>
    
    <item>
      <title>...record audio</title>
      <link>https://hrbosker.github.io/resources/how-to/record-audio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/record-audio/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We&amp;rsquo;ll cover making clean audio recordings in &lt;strong&gt;Audacity&lt;/strong&gt; and in &lt;strong&gt;SpeechRecorder&lt;/strong&gt;. Audacity is easy-to-use and perfect for making a single (long) recording of a speaker. SpeechRecorder presents individual word/sentence prompts to a speaker, saving each utterance separately.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;audacity&#34;&gt;Audacity&lt;/h2&gt;
&lt;p&gt;Audacity is a free, open-source, and cross-platform audio software package. It is easy to use, very intuitive, and fast. It is particularly suited for making a single (long) recording of a speaker, after which you manually extract the relevant words/sentences from this raw recording.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download, install, and open Audacity:&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.audacityteam.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.audacityteam.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;First check the sampling frequency. Typically, 48 kHz or 44.1 kHz will do just fine.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%285%29_hu2376441eede321f8a9da7e7d53920a1d_91532_fcfff5ccd21f291198de3c5bb7eb2094.webp 400w,
               /resources/how-to/record-audio/audacity%20%285%29_hu2376441eede321f8a9da7e7d53920a1d_91532_3ad6b5f589837d118005f71e66a94edd.webp 760w,
               /resources/how-to/record-audio/audacity%20%285%29_hu2376441eede321f8a9da7e7d53920a1d_91532_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%285%29_hu2376441eede321f8a9da7e7d53920a1d_91532_fcfff5ccd21f291198de3c5bb7eb2094.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Audacity&amp;rsquo;s default is to make &lt;em&gt;stereo&lt;/em&gt; recordings, with each recording containing two channels:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%282%29_hu7be07d5036e9b7da3a74763866b1da0f_108602_c15791337c4530288e9b26dcc221855b.webp 400w,
               /resources/how-to/record-audio/audacity%20%282%29_hu7be07d5036e9b7da3a74763866b1da0f_108602_101079cc1c9588fccf33605617292340.webp 760w,
               /resources/how-to/record-audio/audacity%20%282%29_hu7be07d5036e9b7da3a74763866b1da0f_108602_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%282%29_hu7be07d5036e9b7da3a74763866b1da0f_108602_c15791337c4530288e9b26dcc221855b.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;In most cases, it&amp;rsquo;s better to make &lt;em&gt;mono&lt;/em&gt; recordings (with only one channel) to make annotating and manipulating the speech a lot easier. Change the settings at the top to MONO:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%283%29_hu2376441eede321f8a9da7e7d53920a1d_86535_45cf3f591e7a0596c0971f6ee5819e49.webp 400w,
               /resources/how-to/record-audio/audacity%20%283%29_hu2376441eede321f8a9da7e7d53920a1d_86535_2e6d7ff407a4e6ada78768b2c74fe77f.webp 760w,
               /resources/how-to/record-audio/audacity%20%283%29_hu2376441eede321f8a9da7e7d53920a1d_86535_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%283%29_hu2376441eede321f8a9da7e7d53920a1d_86535_45cf3f591e7a0596c0971f6ee5819e49.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Then click the red button to start a recording&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity-%281%29_hu4b45ac301e71be0d2144ce8adc0b578d_82319_cc3d39f0447e3a7c95a9ba21a3bab9e9.webp 400w,
               /resources/how-to/record-audio/audacity-%281%29_hu4b45ac301e71be0d2144ce8adc0b578d_82319_623908e7d9c6dc88c31e511ed137b576.webp 760w,
               /resources/how-to/record-audio/audacity-%281%29_hu4b45ac301e71be0d2144ce8adc0b578d_82319_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity-%281%29_hu4b45ac301e71be0d2144ce8adc0b578d_82319_cc3d39f0447e3a7c95a9ba21a3bab9e9.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;&amp;hellip;which should look something like this:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_91355917154f899b9e63f27b458a3e6d.webp 400w,
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_687d0e6e3ddb5e255870cfd935a13ec7.webp 760w,
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_91355917154f899b9e63f27b458a3e6d.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;When you&amp;rsquo;re done recording, click the yellow square to stop.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%286%29_hu5a8d2d1acc1a5d49f87cae738a910dc5_107877_41b57c8c8d948f1104ab9c5ae4b18710.webp 400w,
               /resources/how-to/record-audio/audacity%20%286%29_hu5a8d2d1acc1a5d49f87cae738a910dc5_107877_fddef4143c77084bfe82d4e714971019.webp 760w,
               /resources/how-to/record-audio/audacity%20%286%29_hu5a8d2d1acc1a5d49f87cae738a910dc5_107877_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%286%29_hu5a8d2d1acc1a5d49f87cae738a910dc5_107877_41b57c8c8d948f1104ab9c5ae4b18710.webp&#34;
               width=&#34;600&#34;
               height=&#34;405&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Do not SAVE projects&lt;/strong&gt; in Audacity, but instead &lt;strong&gt;EXPORT audio files&lt;/strong&gt;. Go to: &lt;em&gt;File &amp;gt; Export Audio&amp;hellip;&lt;/em&gt;, and then click the &amp;lsquo;Save as type&amp;rsquo; drop-down menu to select the file format. Select .wav for uncompressed (raw) audio which is best suited for speech manipulations, or .mp3 for compressed (processed) audio.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Audacity is also great for quickly converting a batch of .wav files to .mp3. Open Audacity, drag a selection of files from a folder into Audacity, and go to &lt;em&gt;File &amp;gt; Export Multiple&lt;/em&gt;. In the pop-up window, select &lt;em&gt;MP3 Files&lt;/em&gt; as &lt;code&gt;Export format&lt;/code&gt;, choose an &lt;code&gt;Export location&lt;/code&gt;, and keep the other defaults (in particular, &lt;code&gt;Split files based on:&lt;/code&gt; &lt;em&gt;Tracks&lt;/em&gt;; &lt;code&gt;Name files:&lt;/code&gt; &lt;em&gt;Using Label/Track Name&lt;/em&gt;). Click &lt;code&gt;Export&lt;/code&gt; and voila, you now have an .mp3 file for each .wav file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;tips-n-tricks&#34;&gt;Tips n tricks&lt;/h3&gt;
&lt;p&gt;But how to make recordings that are &amp;lsquo;clean&amp;rsquo;: with little noise and of good quality?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For longer recordings, ask your speaker to sit in a relaxed position that they can keep up for a longer period of time. People typically tend to slouch during a recording, changing the distance between them and the table mic, thus changing the intensity of speech appearing early vs. later in your recording. If you ask your speaker to try to &amp;lsquo;already slouch a little&amp;rsquo;, this can help avoid large variability in intensity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Before recording your items, start a dummy recording and ask the speaker to count to 100. Then adjust the volume/sensitivity/gain of the microphone. You want the average intensity of the speech to fall roughly in between 0.5 and -0.5 in Audacity. So &lt;strong&gt;this is good&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_91355917154f899b9e63f27b458a3e6d.webp 400w,
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_687d0e6e3ddb5e255870cfd935a13ec7.webp 760w,
               /resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%288%29_hu4b4dab99231e2d53a28bf9b9c2ccdad6_170078_91355917154f899b9e63f27b458a3e6d.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;This is &lt;strong&gt;risky&lt;/strong&gt; because it&amp;rsquo;s approaching 1 and -1:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%284%29_hu2376441eede321f8a9da7e7d53920a1d_100282_98959f412f17659ca2270b433e362987.webp 400w,
               /resources/how-to/record-audio/audacity%20%284%29_hu2376441eede321f8a9da7e7d53920a1d_100282_43e0b7a1bda07f0f2168f38b12caab4d.webp 760w,
               /resources/how-to/record-audio/audacity%20%284%29_hu2376441eede321f8a9da7e7d53920a1d_100282_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%284%29_hu2376441eede321f8a9da7e7d53920a1d_100282_98959f412f17659ca2270b433e362987.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;This is &lt;strong&gt;bad&lt;/strong&gt; because it&amp;rsquo;s outside 1 and -1.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/audacity%20%287%29_hu46cec7b9763626ae177ec4efbcbad4ab_167475_fa51829f8d628713ef0f015d3061c84b.webp 400w,
               /resources/how-to/record-audio/audacity%20%287%29_hu46cec7b9763626ae177ec4efbcbad4ab_167475_6ce8cd8fb0a845cfdc5141be27f94f8c.webp 760w,
               /resources/how-to/record-audio/audacity%20%287%29_hu46cec7b9763626ae177ec4efbcbad4ab_167475_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/audacity%20%287%29_hu46cec7b9763626ae177ec4efbcbad4ab_167475_fa51829f8d628713ef0f015d3061c84b.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;This is called &amp;lsquo;clippings&amp;rsquo; and it&amp;rsquo;s very well audible in the signal. These two audio clips contain the same telephone number, but the first is clean and the second has clippings:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;CLEAN








  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/clean.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;WITH CLIPPINGS








  








&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/clippings.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When boosting the volume/sensitivity/gain of the microphone, be aware that &amp;ndash; by doing so &amp;ndash; you may actually be boosting the background noise too. It&amp;rsquo;s often preferable to move the location of the mic closer to the speaker compared to amplifying the input signal.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you need the mic to be particularly close to the speaker (e.g., when using a head-mounted mic), make sure &lt;strong&gt;the mic is not too close to the speakers lips&lt;/strong&gt; as that will introduce puffs of loud noise for many stop consonants. Better to aim for the chin!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why not ask the speaker to go through your list of items from top to bottom first, and then repeat all items from bottom to top? This will give you two recordings of each item, allowing you to select the best one. Moreover, items at the top and bottom of lists typically sound different from the rest. First items typically have loud intensity and raised pitch, while last items have low intensity and pitch. By switching the order of items, you may be able to circumvent some of these order effects.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;chopping-up-the-recording&#34;&gt;Chopping up the recording&lt;/h3&gt;
&lt;p&gt;When you&amp;rsquo;ve finished recording with Audacity, and have extracted the audio as a .wav file, you will then need to isolate the individual items (e.g., words or sentences) from that one long recording. There&amp;rsquo;s different solutions for this task:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do it by hand.&lt;/strong&gt; Read the .wav file into Praat, create an empty TextGrid, and insert boundaries at the onset and offset of every item. Once you&amp;rsquo;re done, you select the Sound and TextGrid objects together in Praat, and select an option from the Extract menu, such as &lt;code&gt;Extract all intervals...&lt;/code&gt; or &lt;code&gt;Extract non-empty intervals...&lt;/code&gt; and save the individual items.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Go full automatic.&lt;/strong&gt; You can use a forced-aligner to find the words inside your recording. We tend to use &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;WebMAUS&lt;/a&gt; (for word- and phoneme-level annotations) or &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;EasyAlign&lt;/a&gt; (for syllable-level annotations). In both cases, you provide the forced-aligner with the .wav file and a .txt file that contains the orthographic content of the recording (i.e., the prompts that your speaker was asked to read out). The forced-aligner will then try to find the words from the .txt file in the .wav file, providing a .TextGrid file as output.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;However&lt;/em&gt;, often your speaker wasn&amp;rsquo;t perfect, fluffing their lines, repeating items several times before getting it right, or chucking in a few coughs and &amp;lsquo;uhm&amp;rsquo;s here and there. In that case, automatic forced-alignment is suboptimal. In such (commonly occurring) cases, you could consider:&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Go semi-automatic&lt;/strong&gt;. Read your .wav file in Praat and click &lt;em&gt;Annotate &amp;gt; To TextGrid (silences)&amp;hellip;&lt;/em&gt;. Praat will then create a TextGrid for you, labeling silent intervals as &amp;lsquo;silence&amp;rsquo; and intervals with speech as &amp;lsquo;sounding&amp;rsquo;. You can then go through this TextGrid manually and&amp;hellip;
&lt;ol&gt;
&lt;li&gt;&amp;hellip;remove incorrectly detected &amp;lsquo;sounding&amp;rsquo; intervals&lt;/li&gt;
&lt;li&gt;&amp;hellip;adjust the boundaries of individual intervals&lt;/li&gt;
&lt;li&gt;&amp;hellip;label the intervals correctly&lt;/li&gt;
&lt;li&gt;&amp;hellip;extract the intervals for saving and further analysis/manipulation.&lt;br&gt;
(&lt;em&gt;actions (3) and (4) can be performed automatically using scripts in Praat&lt;/em&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/praat%20textgrid%20to%20silences_huaf5bafd9495b95bf7399b1b8ff70f2e4_241763_8d787d42ba7df2968908582761cc1228.webp 400w,
               /resources/how-to/record-audio/praat%20textgrid%20to%20silences_huaf5bafd9495b95bf7399b1b8ff70f2e4_241763_a7f3916459fecd13582f4b7d6dfe0ef0.webp 760w,
               /resources/how-to/record-audio/praat%20textgrid%20to%20silences_huaf5bafd9495b95bf7399b1b8ff70f2e4_241763_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/praat%20textgrid%20to%20silences_huaf5bafd9495b95bf7399b1b8ff70f2e4_241763_8d787d42ba7df2968908582761cc1228.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;I&amp;rsquo;ve found that the default settings for the &lt;code&gt;To TextGrid (silences)&lt;/code&gt; function are best adjusted to: &lt;code&gt;Minimum pitch (Hz) = 50&lt;/code&gt; (instead of the default 100) and &lt;code&gt;Silence threshold (dB) = -40&lt;/code&gt; (instead of the default -32). In my experience, this works considerably better especially for single-word recordings, but often also for full-sentence recordings.&lt;/p&gt;
&lt;p&gt;Oh, and as I&amp;rsquo;m writing this, I see the latest versions of Praat have a new &lt;code&gt;To TextGrid (voice activity)&lt;/code&gt; function. My initial impression is that the default settings for this function perform comparable to the &amp;lsquo;adjusted&amp;rsquo; settings for &lt;code&gt;To TextGrid (silences)&lt;/code&gt; suggested above.&lt;/p&gt;
&lt;h2 id=&#34;speechrecorder&#34;&gt;SpeechRecorder&lt;/h2&gt;
&lt;p&gt;SpeechRecorder is also a free, open-source, and cross-platform audio software package. It takes a little more preparation to use it appropriately compared to Audacity, but an important advantage is that it allows users to &lt;strong&gt;efficiently record multiple individual items&lt;/strong&gt; (instead of one massively long recording). This means that the &amp;lsquo;chopping up recordings into items&amp;rsquo; part of the workflow can be (largely) skipped&amp;hellip; &lt;em&gt;but see &lt;a href=&#34;#trim-silence&#34;&gt;this advice&lt;/a&gt; below&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download, install, and open SpeechRecorder:&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bas.uni-muenchen.de/Bas/software/speechrecorder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.bas.uni-muenchen.de/Bas/software/speechrecorder/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/speechrecorder_1_hub1cc186d544025fb70cb3e12bd4d70a4_137608_1bca9ca60a3d625d8dc0d878c25a9a57.webp 400w,
               /resources/how-to/record-audio/speechrecorder_1_hub1cc186d544025fb70cb3e12bd4d70a4_137608_b4c17a9c98e2a20104ced09e325f85cb.webp 760w,
               /resources/how-to/record-audio/speechrecorder_1_hub1cc186d544025fb70cb3e12bd4d70a4_137608_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/speechrecorder_1_hub1cc186d544025fb70cb3e12bd4d70a4_137608_1bca9ca60a3d625d8dc0d878c25a9a57.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Go to &lt;em&gt;Project &amp;gt; New&lt;/em&gt;, and enter a name for your project&lt;/li&gt;
&lt;li&gt;The directory for the audio output is &lt;code&gt;C:/Users/hanbos/speechrecorder/[myProjectName]/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In the &amp;lsquo;Speaker data&amp;rsquo; window that pops up, add a speaker by clicking &lt;em&gt;Add&lt;/em&gt; and then &lt;em&gt;Select&lt;/em&gt;.
&lt;ul&gt;
&lt;li&gt;If you have multiple talkers, you can add several speakers, and by selecting one of them, you add a speaker identifier to the filename of each audio output file.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Go to &lt;em&gt;Project &amp;gt; Preferences&lt;/em&gt; and find the &lt;em&gt;Recording&lt;/em&gt; tab to change the &lt;em&gt;Format&lt;/em&gt; settings, such as the sampling frequency (e.g., 44.1 or 48 kHz) and the number of channels (usually &lt;em&gt;mono&lt;/em&gt; so 1 channel).&lt;/li&gt;
&lt;li&gt;Then go to &lt;em&gt;Script &amp;gt; Import text table&amp;hellip;&lt;/em&gt; and select a headerless tab-separated file with 2 columns:
&lt;ol&gt;
&lt;li&gt;filenames without extension (e.g., &lt;code&gt;item42_cacao_isolated&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;prompts (e.g., &lt;code&gt;cacao&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    You can easily create a .txt file like this in Excel. In Excel, enter filenames in one column and prompts in another column, select all cells from the two columns, copy them, and paste them into Notepad. If you save this as a .txt file, you will have a headerless tab-separated 2-column file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;SpeechRecorder will then look something like this:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/record-audio/speechrecorder_2_hu0d357699356910442a098a9c0c2bf723_325046_187da9bf15b0ba202cd908ddf8e7e76a.webp 400w,
               /resources/how-to/record-audio/speechrecorder_2_hu0d357699356910442a098a9c0c2bf723_325046_f7788fcf60be0acbb6309b03e7971671.webp 760w,
               /resources/how-to/record-audio/speechrecorder_2_hu0d357699356910442a098a9c0c2bf723_325046_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/record-audio/speechrecorder_2_hu0d357699356910442a098a9c0c2bf723_325046_187da9bf15b0ba202cd908ddf8e7e76a.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Click &lt;em&gt;Record&lt;/em&gt; at the bottom to start a recording. The traffic light will go from Red, to Orange, to Green, after which the speaker pronounces the prompt on screen. Click &lt;em&gt;Stop&lt;/em&gt; to stop the recording.&lt;/li&gt;
&lt;li&gt;If you are happy with the recording, click &lt;strong&gt;[&amp;raquo;]&lt;/strong&gt; to proceed to the next prompt. SpeechRecorder will then save the recording with the appropriate filename in the project folder and present the next prompt.&lt;/li&gt;
&lt;li&gt;However, if you are unhappy with the recording, click &lt;em&gt;Record&lt;/em&gt; again to overwrite the previous take.&lt;/li&gt;
&lt;li&gt;See these &lt;a href=&#34;#tips-n-tricks&#34;&gt;tips n tricks&lt;/a&gt; about how to control audio quality.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;trim-silence&#34;&gt;Trim silence&lt;/h3&gt;
&lt;p&gt;Even though SpeechRecorder gives you separate recordings for individual items, it does often produce recordings with plenty of leading and trailing silence (i.e., before and after the critical word/sentence). There are several options to trim these silent intervals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Change SpeechRecorder settings&lt;/strong&gt;. Go to &lt;em&gt;Project &amp;gt; Preferences&lt;/em&gt;, click the &lt;em&gt;Recording&lt;/em&gt; tab and then the &lt;em&gt;Options&lt;/em&gt; tab. Reduce the &lt;code&gt;default prerecording delay&lt;/code&gt; (default is 1000 ms) and the &lt;code&gt;default postrecording delay&lt;/code&gt; (default is 500 ms) to lower values. &lt;strong&gt;NOTE:&lt;/strong&gt; this will also affect the traffic light behavior (i.e., recordings may start instantly).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use forced alignment&lt;/strong&gt;. Because SpeechRecorder allows the user to re-record items that were fluffed, it typically produces recordings that are easily forced-aligned. We tend to use &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;WebMAUS&lt;/a&gt; (for word- and phoneme-level annotations) or &lt;a href=&#34;https://hrbosker.github.io/resources/other-resources/#videoaudio-editing&#34;&gt;EasyAlign&lt;/a&gt; (for syllable-level annotations). In both cases, you provide the forced-aligner with the .wav file and a .txt file that contains the orthographic content of the recording (i.e., the prompts that your speaker was asked to read out). The forced-aligner will then try to find the words from the .txt file in the .wav file, providing a .TextGrid file as output. Finally, you can use this TextGrid to extract only the intervals of interest, removing leading and trailing silences.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Happy recording!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...annotate in Praat</title>
      <link>https://hrbosker.github.io/resources/how-to/annotate-in-praat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/annotate-in-praat/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    We&amp;rsquo;ll cover making TextGrid annotations in Praat. We&amp;rsquo;ll read a wav file in Praat, create an empty TextGrid with several tiers, add boundaries delimiting individual words and phonemes in the recording, and save the annotations to a TextGrid file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;open-praat&#34;&gt;Open Praat&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Download Praat:&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.fon.hum.uva.nl/praat/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.fon.hum.uva.nl/praat/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;This will download a zipped folder containing a praat.exe file. Save it somewhere where you can find it later, unzip it, and open praat.exe&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s a video tutorial from Matt Winn about downloading Praat: &lt;a href=&#34;https://www.youtube.com/watch?v=QonCpMS5JPg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=QonCpMS5JPg&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;When you open Praat, two windows pop up. One is called Praat Objects (or: object window), and the other is called Praat Picture. Praat Objects is the most important interface for working with sound and annotations, while Praat Picture is where the figures you draw appear (e.g., waveforms or spectrograms) allowing you to save them as .png or .eps files. In most cases, you can ignore Praat Picture and close it.&lt;/li&gt;
&lt;li&gt;In the Objects window, there are fixed menus at the top (Praat, New, Open, Save) and bottom (Rename, Copy, Inspect, Info, Remove). On the right is a dynamic menu, which changes depending on which objects are selected (Sounds, TextGrids, Spectra, etc.).&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/objects_picture_hu1b3ccb0ffc57c9cfcac0c013fdd91d36_96046_1db0e33ff3626c79fe9e709016363b97.webp 400w,
               /resources/how-to/annotate-in-praat/objects_picture_hu1b3ccb0ffc57c9cfcac0c013fdd91d36_96046_d3a280ba0c193eeb99a67f3e35a27fdc.webp 760w,
               /resources/how-to/annotate-in-praat/objects_picture_hu1b3ccb0ffc57c9cfcac0c013fdd91d36_96046_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/objects_picture_hu1b3ccb0ffc57c9cfcac0c013fdd91d36_96046_1db0e33ff3626c79fe9e709016363b97.webp&#34;
               width=&#34;600&#34;
               height=&#34;472&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Why is it called Praat anyway?&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;em&gt;Praat&lt;/em&gt; was created by Paul Boersma and David Weenink, two Dutch speech scientists from Amsterdam. The Dutch word &amp;lsquo;praat&amp;rsquo; &lt;a href=&#34;https://translate.google.nl/?sl=nl&amp;amp;tl=en&amp;amp;text=praat&amp;amp;op=translate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;/pra:t/&lt;/a&gt; is the &lt;a href=&#34;https://www.fon.hum.uva.nl/paul/papers/speakUnspeakPraat_glot2001.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;imperative form&lt;/a&gt; of the verb &amp;rsquo;to speak&amp;rsquo; (so &lt;em&gt;&amp;ldquo;speak!&amp;rdquo;&lt;/em&gt;).&lt;/p&gt;
&lt;/details&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Parts of this how-to are adapted from Aletheia Cui&amp;rsquo;s really clear and helpful &lt;a href=&#34;https://aletheiacui.github.io/tutorials/segmentation_with_praat.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Segmentation with Praat tutorial&lt;/a&gt;, including many of the screenshots. Praat also has a &lt;a href=&#34;http://www.fon.hum.uva.nl/praat/manual/Intro.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Praat manual&lt;/a&gt; itself: it is available online and offline as part of the Praat software. In Praat, go to &lt;em&gt;Help &amp;gt; Praat Intro&lt;/em&gt;. However, the search function in Praat isn&amp;rsquo;t great so often typing a question into Google is more helpful.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;open-a-sound-file&#34;&gt;Open a sound file&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open a sound file: &lt;em&gt;Open &amp;gt; Read from file&amp;hellip;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The file will show up as a Sound object in the object window, and upon opening will already automatically be selected (highlighted in blue)&lt;/li&gt;
&lt;li&gt;Note that Praat, like me, has a serious dislike for spaces in filenames. If your file is called &amp;ldquo;file number one.wav&amp;rdquo;, Praat will present it in the object window as &amp;ldquo;file_number_one&amp;rdquo;, replacing spaces with underscores. This will for instance affect the default name when saving the object in Praat. So here&amp;rsquo;s a free piece of advice: &lt;em&gt;better avoid spaces in filenames&amp;hellip;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;You can view the sound by clicking &lt;em&gt;View &amp;amp; Edit&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;This will show the sound waveform (oscillogram) on top and a spectrogram below that.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/soundeditor_hu946c1ff79d5b8f4d64dbd230b6747996_298555_87a44014db3acbf9b47a6dbd8554d11c.webp 400w,
               /resources/how-to/annotate-in-praat/soundeditor_hu946c1ff79d5b8f4d64dbd230b6747996_298555_6dff94be66fd37544cfe8db90c130f2d.webp 760w,
               /resources/how-to/annotate-in-praat/soundeditor_hu946c1ff79d5b8f4d64dbd230b6747996_298555_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/soundeditor_hu946c1ff79d5b8f4d64dbd230b6747996_298555_87a44014db3acbf9b47a6dbd8554d11c.webp&#34;
               width=&#34;600&#34;
               height=&#34;404&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;h2 id=&#34;zooming-and-playing&#34;&gt;Zooming and playing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You can zoom in to a different parts of the recording by clicking and dragging inside the waveform to select a part and click &lt;code&gt;[sel]&lt;/code&gt; or [CTRL+N] in the bottom left to zoom in to this part. You can also use &lt;code&gt;bak&lt;/code&gt; [CTRL+B] to go back to the previous view, &lt;code&gt;[all]&lt;/code&gt; [CTRL+A] to view the entire sound file, and &lt;code&gt;[in]&lt;/code&gt; [CTRL+I] and &lt;code&gt;[out]&lt;/code&gt; [CTRL+O] to gradually zoom in and out.&lt;/li&gt;
&lt;li&gt;You can play parts of the sound by selecting an interval and hitting [TAB] to play and [ESCAPE] to stop the playback. This is identical to clicking on the interval appearing in the first gray bar at the very bottom of the TextGrid window. Clicking on the second gray bar will play the visible window, while clicking on the third and last gray bar will play the entire sound.&lt;/li&gt;
&lt;li&gt;Now close the Sound window because we do not only want to &lt;em&gt;view&lt;/em&gt; the sound, we also want to &lt;em&gt;annotate&lt;/em&gt; it in a TextGrid.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;create-a-textgrid&#34;&gt;Create a TextGrid&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Go back to the Praat object window, select the Sound by clicking on it (if it wasn&amp;rsquo;t selected already), and click &lt;em&gt;Annotate &amp;gt; To TextGrid&amp;hellip;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Praat will then ask you for the names of tiers. Each TextGrid can have multiple tiers, combining for instance word-level annotations (longer intervals demarcating individual words), syllable-level annotations (shorter intervals demarcating the syllables inside the words), and phoneme-level annotations (short intervals demarcating the individual sounds).&lt;/li&gt;
&lt;li&gt;Tiers inside TextGrids come in two flavors: interval tiers and point tiers. Interval tiers allow you to add &amp;lsquo;boundaries&amp;rsquo; that demarcate certain acoustic events (words, syllables, phonemes), indicating where they are and how long they are. For word-level annotations in an interval tier, you&amp;rsquo;d need two boundaries to demarcate a single word: one at its onset and another at its offset. Point tiers allow you to add &amp;lsquo;points&amp;rsquo; that identify certain individual time points, but not the intervals between time points. &lt;strong&gt;Interval tiers are the most commonly used type of tier&lt;/strong&gt;, so we&amp;rsquo;ll primarily focus on interval tiers.&lt;/li&gt;
&lt;li&gt;Enter the names of your interval tiers in the top field, separated by space (e.g., &lt;code&gt;word phoneme&lt;/code&gt;), and click OK. If you want any of these to be point tiers instead of interval tiers, copy the name of the point tier in the second field (e.g., &lt;code&gt;word phoneme F1 F2&lt;/code&gt; in the first field, defining &lt;code&gt;F1 F2&lt;/code&gt; in the second field as point tiers).&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/to_tg_hu8ee2ec56f2975846d71d30f3dca084f2_98091_f4abe1f1146350bdac8c0a1107007309.webp 400w,
               /resources/how-to/annotate-in-praat/to_tg_hu8ee2ec56f2975846d71d30f3dca084f2_98091_bf28b811b1fe8870296d1fb479840903.webp 760w,
               /resources/how-to/annotate-in-praat/to_tg_hu8ee2ec56f2975846d71d30f3dca084f2_98091_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/to_tg_hu8ee2ec56f2975846d71d30f3dca084f2_98091_f4abe1f1146350bdac8c0a1107007309.webp&#34;
               width=&#34;600&#34;
               height=&#34;320&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;ll find a new object appear in the object window, namely a(n empty) TextGrid object with the same name as the Sound object. Also, it is selected automatically (highlighted in blue).&lt;/li&gt;
&lt;li&gt;Select both the Sound object and the TextGrid object (clicking while holding [SHIFT] or [CTRL]) together, and click &lt;em&gt;View and Edit&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/view_edit_hu56544f61f252b41f9159be213f8b0a30_235320_cbed4e8850b60798b2bdcad2daa5757d.webp 400w,
               /resources/how-to/annotate-in-praat/view_edit_hu56544f61f252b41f9159be213f8b0a30_235320_c4be26d213fa656f4455cddcfa1830d4.webp 760w,
               /resources/how-to/annotate-in-praat/view_edit_hu56544f61f252b41f9159be213f8b0a30_235320_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/view_edit_hu56544f61f252b41f9159be213f8b0a30_235320_cbed4e8850b60798b2bdcad2daa5757d.webp&#34;
               width=&#34;600&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;ll see a new window, with the waveform on top, then a spectrogram, and then the various tiers of the TextGrid appearing below. You&amp;rsquo;ll find the names for the various tiers (that you defined in the previous step) appear on the right.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/tg_window_hu0428fc244bf14a2c34e1b264ed061132_316880_b9bc643e46a7a99d148904814aab5011.webp 400w,
               /resources/how-to/annotate-in-praat/tg_window_hu0428fc244bf14a2c34e1b264ed061132_316880_20d34257e7ce2e1f90664f56affc4110.webp 760w,
               /resources/how-to/annotate-in-praat/tg_window_hu0428fc244bf14a2c34e1b264ed061132_316880_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/tg_window_hu0428fc244bf14a2c34e1b264ed061132_316880_b9bc643e46a7a99d148904814aab5011.webp&#34;
               width=&#34;600&#34;
               height=&#34;633&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;Now you can start editing the TextGrid by adding &amp;lsquo;boundaries&amp;rsquo; (in interval tiers) and &amp;lsquo;points&amp;rsquo; (in point tiers). We&amp;rsquo;ll first focus on word-level annotations, identifying the onset and offset of individual words.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;segment-words&#34;&gt;Segment words&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Select a time window in the waveform that contains your word of interest, and click &lt;code&gt;[sel]&lt;/code&gt; [CTRL+N].&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s often wise to select a rather generous interval around a word of interest. This allows you to then select the &amp;rsquo;true&amp;rsquo; onset and offset of the word with greater precision and without missing anything.&lt;/li&gt;
&lt;li&gt;Now that you see the word in greater detail, we&amp;rsquo;ll segment it.&lt;/li&gt;
&lt;li&gt;Click inside the waveform at the word onset and drag to the word offset. This will select the word inside the waveform. Hit [CTRL+,] to move the left boundary of the selection to a zero-crossing, [CTRL+.] to move the right boundary of the selection to a zero-crossing, and then [ENTER] to create an interval in the top tier of the TextGrid (top tier selected by default).&lt;/li&gt;
&lt;li&gt;Instead of adding an entire interval (i.e, two boundaries) in one go, you can also click on an individual time point in the waveform, hit [CTRL+0] to move to the nearest zero-crossing, and then hit [ENTER] to insert a single boundary.&lt;/li&gt;
&lt;li&gt;You can still adjust the boundaries by dragging them around with the mouse. However, there&amp;rsquo;s no keyboard shortcut to move a pre-existing boundary to a zero-crossing: you&amp;rsquo;ll have to do this manually by selecting it and going to &lt;em&gt;Boundary &amp;gt; Move to nearest zero crossing&lt;/em&gt;. Consequently, it&amp;rsquo;s often easier to simply remove a boundary [ALT + BACKSPACE], click at the new location, hit [CTRL+0] and [ENTER] to place the new boundary.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/add_interval_huedf5541d0db3d0b2753ea11aa888fd67_256852_c899439b2b372b5d284cfe91e203ff8d.webp 400w,
               /resources/how-to/annotate-in-praat/add_interval_huedf5541d0db3d0b2753ea11aa888fd67_256852_a4e66d305367484eceda033f848690db.webp 760w,
               /resources/how-to/annotate-in-praat/add_interval_huedf5541d0db3d0b2753ea11aa888fd67_256852_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/add_interval_huedf5541d0db3d0b2753ea11aa888fd67_256852_c899439b2b372b5d284cfe91e203ff8d.webp&#34;
               width=&#34;600&#34;
               height=&#34;511&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;&lt;strong&gt;Always select time points at positive-going zero-crossings!&lt;/strong&gt; This is particularly important when you want to extract intervals from a sound file and manipulate them (but less important if you only want to measure certain acoustic features, such as intensity or F0, without extracting/manipulating anything).&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;em&gt;Why should I?&lt;/em&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Sound is a wave of air pressure. Imagine we have two pure tones of 440 Hz, but one starts at a positive-going zero-crossing (&lt;code&gt;phase = 0°&lt;/code&gt;; signal A) and the other at a point of high air pressure (&lt;code&gt;phase = 1/2π&lt;/code&gt;; signal B). If we then concatenate these two sounds (signal C), and play the concatenation (see below figure), our speakers need to jump from 0 to 1 near instantaneously. This will result in an audible click. &lt;strong&gt;NOTE:&lt;/strong&gt; concatenating two tones that both start at a zero-crossing, but one starts at a &lt;em&gt;positive-going&lt;/em&gt; zero-crossing and the other at a &lt;em&gt;negative-going&lt;/em&gt; zero-crossing, also results in audible artifacts (signal D). Therefore, it&amp;rsquo;s advisable to consistently select time points at &lt;em&gt;positive-going zero-crossings&lt;/em&gt;. If you want to manually inspect this, select a tiny time interval around a boundary in Praat and click &lt;code&gt;[sel]&lt;/code&gt; [CTRL+N].&lt;/p&gt;
&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/zerocrossings_hufec699dee811b6475d5f5a4d49e10963_284571_4e8af0f1c49eb867e7b173ccc3adff54.webp 400w,
               /resources/how-to/annotate-in-praat/zerocrossings_hufec699dee811b6475d5f5a4d49e10963_284571_15a1eb025ede2e3860056b4e69d9d6fb.webp 760w,
               /resources/how-to/annotate-in-praat/zerocrossings_hufec699dee811b6475d5f5a4d49e10963_284571_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/zerocrossings_hufec699dee811b6475d5f5a4d49e10963_284571_4e8af0f1c49eb867e7b173ccc3adff54.webp&#34;
               width=&#34;600&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;This is signal C, can you hear a &amp;lsquo;click&amp;rsquo; midway in the recording?&lt;/em&gt;&lt;/p&gt;
&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/concat1.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
&lt;p&gt;&lt;em&gt;This is signal D, can you again hear a &amp;lsquo;click&amp;rsquo; midway in the recording?&lt;/em&gt;&lt;/p&gt;
&lt;audio controls &gt;
  &lt;source src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/concat2.mp3&#34; type=&#34;audio/mpeg&#34;&gt;
&lt;/audio&gt;
&lt;/p&gt;
&lt;/details&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;segment-phonemes&#34;&gt;Segment phonemes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The two boundaries you just added demarcate the word, but they also form the onset of the first phoneme, and the offset of the last phoneme inside the word. Extend the first boundary in the first &lt;em&gt;word&lt;/em&gt; tier to the second &lt;em&gt;phoneme&lt;/em&gt; tier by clicking on it (blue line turns red) and then click the small circle appearing just below it (inside the second tier). This will place a boundary in the second tier at the exact same time point as in the first tier.&lt;/li&gt;
&lt;li&gt;Now place additional individual boundaries at the onsets and offsets of the various phonemes inside the word in the second &lt;em&gt;phoneme&lt;/em&gt; tier. First click anywhere on the second tier to select it, then click on a time point in the waveform, and hit [ENTER] to place a boundary.&lt;/li&gt;
&lt;li&gt;You can play intervals to verify if they are accurate. Click on an interval to select it and hit [TAB] to play it and [ESCAPE] to stop the playback. This is identical to clicking on the interval appearing in the first gray bar at the very bottom of the TextGrid window. Clicking on the second gray bar will play the visible window, while clicking on the third and last gray bar will play the entire sound.&lt;/li&gt;
&lt;li&gt;Now let&amp;rsquo;s label the individual intervals. Click on an interval and simply type in a label. It will appear inside the interval. You can also edit it in the utmost top left of the TextGrid window.&lt;/li&gt;
&lt;li&gt;The final result could then look something like this:&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/annotate-in-praat/pat_segmented_hu87f8ccd721fd1472408c416483e2ac11_509251_5315503b0fc7e11a0e63a548ba1dec05.webp 400w,
               /resources/how-to/annotate-in-praat/pat_segmented_hu87f8ccd721fd1472408c416483e2ac11_509251_3935f0d40eb8664271d0acac9bd14f62.webp 760w,
               /resources/how-to/annotate-in-praat/pat_segmented_hu87f8ccd721fd1472408c416483e2ac11_509251_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/annotate-in-praat/pat_segmented_hu87f8ccd721fd1472408c416483e2ac11_509251_5315503b0fc7e11a0e63a548ba1dec05.webp&#34;
               width=&#34;600&#34;
               height=&#34;511&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;h2 id=&#34;working-with-textgrids&#34;&gt;Working with TextGrids&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You can quickly scroll through TextGrids by clicking on an interval and then hitting [ALT + →] to see the next one, or [ALT + ←] to see the previous one. Similarly, use [ALT + ↓] and [ALT + ↑] to go up or down a tier.&lt;/li&gt;
&lt;li&gt;You can easily remove boundaries by selecting an interval and hitting [ALT + BACKSPACE]. This will remove the left boundary of the interval.&lt;/li&gt;
&lt;li&gt;If you want to remove multiple boundaries in a row, you hit [ALT + BACKSPACE], [ALT + →], [ALT + BACKSPACE], [ALT + →], etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;saving-the-textgrid&#34;&gt;Saving the TextGrid&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Save frequently! If Praat crashes, you will lose all your recent work unless you save regularly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Save from the TextGrid Editor window. Just hit [Ctrl+S] which will bring up a dialogue window that allows you to specify the name and location of the new .TextGrid file. &lt;strong&gt;NOTE:&lt;/strong&gt; Even though you see the waveform in the TextGrid Editor window, saving in this way &lt;em&gt;only&lt;/em&gt; saves the TextGrid (i.e., everything in the tiers), &lt;em&gt;not&lt;/em&gt; the Sound!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; Save from the Praat object window. Select the TextGrid object (highlighting it in blue) and go to &lt;em&gt;Save &amp;gt; Save as text file&lt;/em&gt;. This will bring up the same dialogue window. Do &lt;strong&gt;not&lt;/strong&gt; select both the Sound and TextGrid objects; you only want to save your annotations inside the tiers in the TextGrid.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lets-automate-this&#34;&gt;Let&amp;rsquo;s automate this&lt;/h2&gt;
&lt;p&gt;Praat has a scripting interface that allows you to enter code to perform certain functions in a much faster and more efficient way. See our &lt;a href=&#34;https://hrbosker.github.io/resources/how-to/script-in-praat/&#34;&gt;How to script in Praat&lt;/a&gt; to get you acquainted with the Praat scripting interface.&lt;/p&gt;
&lt;p&gt;Once you&amp;rsquo;re familiar with Praat scripting, check out our &lt;a href=&#34;https://hrbosker.github.io/resources/scripts/annotate/&#34;&gt;annotation script&lt;/a&gt;. This script reads all files in a given folder, presents them to the user for manual annotation, and when the user clicks &lt;em&gt;Next&lt;/em&gt; to proceed Praat will automatically save the user&amp;rsquo;s annotations and present the next file for annotation. This speeds up an annotation workflow considerably.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Happy Praat&amp;rsquo;ing!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...script in Praat</title>
      <link>https://hrbosker.github.io/resources/how-to/script-in-praat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/script-in-praat/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Here&amp;rsquo;s a brief intro into the Praat scripting language. We&amp;rsquo;ll cover how to write and run a script, point you to some tutorials, highlight some of the strange quirks in the Praat scripting language, and provide some scripts we find useful ourselves.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;run-your-first-script&#34;&gt;Run your first script&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open Praat, and go to &lt;em&gt;Praat &amp;gt; New Praat script&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /resources/how-to/script-in-praat/open_praatscript_hu29fd31b82b883422b501bc54a996c18a_102016_648680a9fd9ccb6d0d83159659fbf19e.webp 400w,
               /resources/how-to/script-in-praat/open_praatscript_hu29fd31b82b883422b501bc54a996c18a_102016_79ec0d38c66cbe4e36be51cf33f4663e.webp 760w,
               /resources/how-to/script-in-praat/open_praatscript_hu29fd31b82b883422b501bc54a996c18a_102016_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://hrbosker.github.io/resources/how-to/script-in-praat/open_praatscript_hu29fd31b82b883422b501bc54a996c18a_102016_648680a9fd9ccb6d0d83159659fbf19e.webp&#34;
               width=&#34;668&#34;
               height=&#34;562&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;ll find a rather empty-looking window popping up on your screen, with the menus &lt;em&gt;File, Edit, Search, Convert, Font, Run&lt;/em&gt; at the top.&lt;/li&gt;
&lt;li&gt;Now type this into that scripting window:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Create Sound from formula: &amp;#34;demo&amp;#34;, 1, 0, 1, 44100, &amp;#34;1/2 * sin(2*pi*377*x)&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Play
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Now turn on your speakers&amp;hellip;&lt;/li&gt;
&lt;li&gt;&amp;hellip;and click &lt;em&gt;Run &amp;gt; Run&lt;/em&gt; or hit [CTRL+R] to execute the script.&lt;/li&gt;
&lt;li&gt;Congratulations, you&amp;rsquo;ve run your first script that creates and plays a short 377 Hz tone.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;every-line-is-a-click&#34;&gt;Every line is a click&lt;/h2&gt;
&lt;p&gt;The Praat scripting language is a Graphical User Interface (GUI) scripting language. This means that, put rather bluntly, &lt;strong&gt;every line in the script is like a click in the Praat object window&lt;/strong&gt;. The two lines in the code above are identical to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;selecting &lt;em&gt;New &amp;gt; Sound &amp;gt; Create Sound from formula&amp;hellip;&lt;/em&gt;, and entering some parameters&lt;/li&gt;
&lt;li&gt;clicking Play&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This also means that you can click around in Praat and then ask Praat to give you the code for those particular clicks. That is, Praat actually keeps track of every click you perform.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to the scripting window&lt;/li&gt;
&lt;li&gt;click &lt;em&gt;Edit &amp;gt; Paste history&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This asks Praat to paste every action you performed since opening Praat. This is particularly handy when you don&amp;rsquo;t know how to script a certain action. For instance, you wanna know how to open a sound file in Praat using a script?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to the Praat object window&lt;/li&gt;
&lt;li&gt;click &lt;em&gt;Open &amp;gt; Read from file&amp;hellip;&lt;/em&gt; and open a sound file&lt;/li&gt;
&lt;li&gt;Now go to the scripting window&lt;/li&gt;
&lt;li&gt;click &lt;em&gt;Edit &amp;gt; Paste history&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It should show you something along the lines of:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Read from file: &amp;#34;C:\Users\hanbos\mysounds\demo.wav&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;but then with a different directory and filename.&lt;/p&gt;
&lt;p&gt;So remember: &lt;strong&gt;perform the functions in the object window, paste history in the scripting window, and edit the code from there&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;tutorials&#34;&gt;Tutorials&lt;/h2&gt;
&lt;p&gt;Praat offers a scripting tutorial itself. Go to &lt;em&gt;Help &amp;gt; Praat Intro&lt;/em&gt; and scroll down to find &lt;em&gt;Scripting&lt;/em&gt;. Alternatively, go to &lt;a href=&#34;https://www.fon.hum.uva.nl/praat/manual/Scripting.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.fon.hum.uva.nl/praat/manual/Scripting.html&lt;/a&gt;. This tutorial is not too bad actually. Other third-party tutorials are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.eleanorchodroff.com/tutorial/PraatScripting.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.eleanorchodroff.com/tutorial/PraatScripting.pdf&lt;/a&gt;: some quick intro slides by Eleanor Chodroff&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://praatscripting.lingphon.net&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://praatscripting.lingphon.net&lt;/a&gt;: a &lt;strong&gt;comprehensive written tutorial&lt;/strong&gt; by Jörg Mayer&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://praatscriptingtutorial.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://praatscriptingtutorial.com/&lt;/a&gt;: a &lt;strong&gt;comprehensive written tutorial&lt;/strong&gt; by Daniel Riggs&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mauriciofigueroa.cl/04_scripts/04_scripts.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.mauriciofigueroa.cl/04_scripts/04_scripts.html&lt;/a&gt;: a &lt;strong&gt;comprehensive written tutorial&lt;/strong&gt; by Mauricio A. Figueroa Candia&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;strange-quirks&#34;&gt;Strange quirks&lt;/h2&gt;
&lt;p&gt;Praat has some peculiarities that make the Praat scripting language stand out compared to other languages, like &lt;em&gt;python&lt;/em&gt; and &lt;em&gt;R&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Over the years, Praat has had three types of syntax. Current Praat versions are compatible with older and newer syntax types, and mixes thereof.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# This line of code extracts the first 100 ms of a sound object...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# ... in Praat versions 5.3.43 and older; before April 2013
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Extract part... 0 0.1 rectangular 1 no
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# ... in Praat versions between 5.3.44 and 5.3.62; April 2013 - January 2014
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;do(&amp;#34;Extract part&amp;#34;, 0, 0.1, &amp;#34;rectangular&amp;#34;, 1, &amp;#34;no&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# ... in Praat versions 5.3.63 and later; after January 2014
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Extract part: 0, 0.1, &amp;#34;rectangular, 1, &amp;#34;no&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Praat variables &lt;strong&gt;always&lt;/strong&gt; start in lowercase. Capitals are reserved for functions:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;play = 2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;for i to play
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Play
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;endfor
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Praat does not distinguish between single and double equal signs:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;intensityLevel = 75
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;if intensityLevel = 75
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    newIntensityLevel = 80
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;endif
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Praat uses single quotes to access the value of a variable. This is, for instance, important when concatenating the values of different string variables:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myDirectory$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myFilename$ = &amp;#34;demo.wav&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Read from file: &amp;#34;&amp;#39;myDirectory$&amp;#39;\&amp;#39;myFilename$&amp;#39;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Praat&amp;rsquo;s spelling is &lt;code&gt;elsif&lt;/code&gt;, &lt;strong&gt;not&lt;/strong&gt; &lt;code&gt;elseif&lt;/code&gt; (don&amp;rsquo;t ask me why&amp;hellip;)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;if intensityLevel = 80
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Scale intensity: 75
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;elsif intensityLevel = 75
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Scale intensity: 80
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;else
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Scale intensity: 65
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;endif
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Different objects in Praat have different functions. For Sound objects, you can run functions like &lt;code&gt;Play&lt;/code&gt;, &lt;code&gt;Resample...&lt;/code&gt;, &lt;code&gt;Scale intensity...&lt;/code&gt;, etc., while for TextGrid objects, you can run functions like &lt;code&gt;Duplicate tier...&lt;/code&gt;, &lt;code&gt;Insert boundary...&lt;/code&gt;, etc. Therefore, it is important to &lt;strong&gt;keep track of which object is selected&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myDirectory$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myFilename$ = &amp;#34;demo.wav&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Read from file: &amp;#34;&amp;#39;myDirectory$&amp;#39;\&amp;#39;myFilename$&amp;#39;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;To TextGrid: &amp;#34;words&amp;#34;, &amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Play
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&amp;hellip; will throw an error because the newly created TextGrid is automatically selected after &lt;code&gt;To TextGrid:&lt;/code&gt; and Praat cannot play TextGrids. The solution is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myDirectory$ = &amp;#34;C:\Users\hanbos\mysounds&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;myFilename$ = &amp;#34;demo.wav&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Read from file: &amp;#34;&amp;#39;myDirectory$&amp;#39;\&amp;#39;myFilename$&amp;#39;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;To TextGrid: &amp;#34;words&amp;#34;, &amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;select Sound demo
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Play
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ready-made-scripts&#34;&gt;Ready-made scripts&lt;/h2&gt;
&lt;p&gt;See our &lt;a href=&#34;https://hrbosker.github.io/resources/scripts/&#34;&gt;Scripts&lt;/a&gt; archive for snippets of code we frequently use. Note, however, that &lt;strong&gt;they require customization&lt;/strong&gt; for each individual new project. &lt;em&gt;Use at your own risk!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Other scripts resources available online are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.praatvocaltoolkit.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vocal Toolkit plugin&lt;/a&gt; is a plugin for Praat. When installed, you can call various new functions from a button within Praat. However, it&amp;rsquo;s a little risky if you don&amp;rsquo;t know the ins-and-outs of a particular function, so &lt;strong&gt;always check the raw code&lt;/strong&gt; here:
&lt;ul&gt;
&lt;li&gt;[WINDOWS] &amp;ldquo;C:\Users\&lt;em&gt;(Username)&lt;/em&gt;\Praat\plugin_VocalToolkit&amp;rdquo;&lt;/li&gt;
&lt;li&gt;[MAC] &amp;ldquo;/Users/&lt;em&gt;(UserName)&lt;/em&gt;/Library/Preferences/Praat Prefs/&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mattwinn.com/praat.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matt Winn&amp;rsquo;s Listen Lab&lt;/a&gt; with some really fun &lt;a href=&#34;https://www.youtube.com/playlist?list=PL6niCBwOhjHga4bCS83VJ2uKzQ8ZjEVeG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Youtube Praat tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://holgermitterer.eu/research.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Holger Mitterer&amp;rsquo;s website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/stylerw/styler_praat_scripts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Will Styler&amp;rsquo;s repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;praatvscode&#34;&gt;PraatVSCode&lt;/h2&gt;
&lt;p&gt;The scripting interface in Praat itself is not the best. It&amp;rsquo;s basically a plain text editor with a Run button. There&amp;rsquo;s no syntax highlighting, no autocompletion, no regular expression search options&amp;hellip;&lt;/p&gt;
&lt;p&gt;Therefore, many users tend to write and edit their scripts in other editors, like TextPad, Notepad++, or Sublime. Some of these even provide things like syntax highlighting and autocompletion, see &lt;a href=&#34;https://praatpfanne.lingphon.net/praat-ressourcen/resources-english/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this overview&lt;/a&gt; for editor plugins for Sublime, Kate, Atom, Notepad++, Vim, and Ace. However, &lt;strong&gt;none of these can run Praat code&lt;/strong&gt;. Instead, users need to write their code in Notepad++, copy it, paste it into Praat, and then hit Run. You can&amp;rsquo;t imagine how cumbersome this is and it can introduce all sorts of human errors.&lt;/p&gt;
&lt;p&gt;A great solution is &lt;a href=&#34;https://hrbosker.github.io/resources/tools/#praatvscode&#34;&gt;PraatVSCode&lt;/a&gt;:&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/orhunulusahin/praatvscode/blob/main/assets/syntax_after.png?raw=true&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;600&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;Created by our very own &lt;a href=&#34;https://hrbosker.github.io/author/orhun-ulusahin/&#34;&gt;Orhun Uluşahin&lt;/a&gt;, PraatVSCode is an extension for Visual Studio Code, providing syntax highlighting, autocompletion, and even an array of code snippets that writes itself. Moreover, it allows &lt;strong&gt;running of scripts by Praat from inside Visual Studio Code&lt;/strong&gt;. &lt;a href=&#34;https://hrbosker.github.io/resources/tools/#praatvscode&#34;&gt;Try it now!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Happy coding!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...run a power analysis</title>
      <link>https://hrbosker.github.io/resources/how-to/run-a-power-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/run-a-power-analysis/</guid>
      <description>&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    This R script runs a simulation-based power analysis for a simple 2AFC experimental design. This is &lt;strong&gt;by no means&lt;/strong&gt; a one-size-fits-all solution to all your power needs. &lt;em&gt;Use at your own risk!&lt;/em&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The R script shared here is first and foremost intended as a &lt;strong&gt;lab template&lt;/strong&gt;, providing code that we adjust each time we run a new 2AFC (two alternative forced choice) experiment. This means &lt;strong&gt;it requires customization&lt;/strong&gt; for each individual new project.&lt;/p&gt;
&lt;p&gt;It is based on &lt;a href=&#34;https://doi.org/10.3758/s13428-021-01546-0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kumle et al. (2021, BRM)&lt;/a&gt;, adapting code from its github repo (Scenario #3) to fit our needs. It runs a simulation-based GLMM power analysis with 1000 iterations for a 2AFC design with {10, 20, 30, 40, 50} participants, each presented with 100 trials sampling from a single 5-step phonetic continuum. The estimates for fixed effects and random effects are drawn from pilot data, but can also be adopted from previous literature.&lt;/p&gt;
&lt;p&gt;The script can be adjusted to run LMM power analysis (instead of GLMM) and to include &amp;gt;1 random effects; see comments in script.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Download the &lt;a href=&#34;R_power_analysis.R&#34;&gt;R_power_analysis.R&lt;/a&gt; script here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Hans Rutger Bosker, Radboud University Nijmegen&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### SPEAC research group, hrbosker.github.io&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### HansRutger.Bosker@ru.nl&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### License: CC BY-NC 4.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Last updated: July 20, 2022&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Code adapted from Kumle et al. (2021, Behavior Research Methods)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### doi: 10.3758/s13428-021-01546-0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### who introduced the R package &amp;#39;mixedpower&amp;#39; comparing it to &amp;#39;simr&amp;#39;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Specifically: https://lkumle.github.io/power_notebooks/Scenario3_notebook.html&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#####           and https://github.com/lkumle/analyses_power_tutorial/blob/master/Scenario%203/Analysis_Scenario3.R&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### In its present form, the script runs a simulation-based GLMM power analysis&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### for a 2AFC experimental design with 20 participants and 100 trials per pp.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### BinomResp is the binomial dependent variable of 0s and 1s.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Predictors are Group (between-participant) and ScaledStep (within-participant).&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#####	&amp;gt; For LMMs, see: https://lkumle.github.io/power_notebooks/Scenario3_notebook.html &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### 	&amp;gt; For adding additional random effects, see suggestions in script below.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# REQUIRED PACKAGES&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lme4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;simr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# for comparison to mixedpower&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Apparently, &amp;#39;mixedpower&amp;#39; does not live on the &amp;#39;default&amp;#39; package R server.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### In order to install it, you need another package &amp;#39;remotes&amp;#39; to access it.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Note: you only need to install these packages once. Once they&amp;#39;re installed,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### simply running the library() statements suffices.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#install.packages(&amp;#34;remotes&amp;#34;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#library(remotes)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#remotes::install_github(&amp;#34;DejanDraschkow/mixedpower&amp;#34;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mixedpower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# RETRIEVING ESTIMATES FROM PILOT DATA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pilot&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;read.table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;pilotdata.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sep&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;\t&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;header&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ppid = participant number (hence, a unique entry for each pp)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# trialnr = test item order (1:100)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# step = step on the test continuum: 1,2,3,4,5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# stepscaled = scaled version of step (z-scored), resulting from: scale(pilot$step)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# group = group, with 2 levels: Group_1 or Group_2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# group_devcod = deviance coded &amp;#39;group&amp;#39;: -0.5 is Group_1, +0.5 is Group_2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# BinomResp = binomial coding of participants&amp;#39; responses (0s and 1s)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pilot_m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;glmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BinomResp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;group_devcod&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stepscaled&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                   &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ppid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                 &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pilot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;family&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;binomial&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pilot_m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# CREATING ARTIFICIAL DATA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### This creates a dataset in which 20 participants are presented 100 trials each.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### Half of the participants are assigned to Group 1, the other half to Group 2.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### The 100 trials per participant include steps 1, 2, 3, 4, and 5 from a phonetic continuum.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### So each step is repeated 20 times per participant.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1: RANDOM EFFECTS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# including variables used as random effects in artificial data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;number_of_participants&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;number_of_trials_per_participant&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;expand.grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TrialID&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;number_of_trials_per_participant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                               &lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;number_of_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# At present, the script is designed for an analysis with only 1 random intercept.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# If requiring &amp;gt;1 random effects&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ...adjust the &amp;#39;artificial_data&amp;#39;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ...add an estimate for &amp;#39;estim_ran_effs&amp;#39;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# ...adjust the &amp;#39;artificial_glmer&amp;#39;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;							   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2. FIXED EFFECTS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#  generate continuum steps&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;continuum_steps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# repeat for every ParticipantID in data (e.g., 20 times)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_data[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Continuum_step&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;continuum_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;number_of_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScaledStep&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;scale&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Continuum_step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# include group&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_data[&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Group&amp;#34;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_data[artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;number_of_participants&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;-0.5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.factor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3. VERIFICATION OF DATAFRAME DESIGN&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Continuum_step&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;TrialID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# CREATING ARTIFICIAL MODEL&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### See summary(pilot_m) above for random and fixed effect estimates.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# summary(pilot_m)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### estim_fix_effs &amp;lt;- c(intercept, firstSimpleEffect, secondSimpleEffect, interaction)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;estim_fix_effs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.125&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.838&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;-1.072&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### estim_ran_effs &amp;lt;- c(firstRandomIntercept, secondRandomIntercept)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;estim_ran_effs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.627&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### NOTE: it is very important that the order of estimates in &amp;#39;estim_fix_effs&amp;#39; and &amp;#39;estim_ran_effs&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### 	is identical to the other of predictors in &amp;#39;artificial_glmer&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#####	and in &amp;#39;power_S3&amp;#39; below.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;artificial_glmer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;makeGlmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;formula&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;BinomResp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Group&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ScaledStep&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ParticipantID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                              &lt;span class=&#34;n&#34;&gt;fixef&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;estim_fix_effs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;VarCorr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;estim_ran_effs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                              &lt;span class=&#34;n&#34;&gt;family&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;binomial&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;artificial_glmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### NOTE: at present, only testing for two simple effects without interaction&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##### and a single random intercept for Participants.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# POWER ANALYSIS&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;########################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# USING THE PACKAGE simr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#power_simr &amp;lt;- powerSim(fit = artificial_glmer, test = fixed(&amp;#34;Group&amp;#34;), nsim = 1000)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#print(power_simr)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# USING THE PACKAGE mixedpower&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# SESOI = Smallest Effect Size Of Interest&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# A simple justification strategy is to reduce all beta coefficients by 15%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;power_mixed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mixedpower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;artificial_glmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;artificial_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       &lt;span class=&#34;n&#34;&gt;fixed_effects&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Group&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;ScaledStep&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       &lt;span class=&#34;n&#34;&gt;simvar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;ParticipantID&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;steps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;40&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       &lt;span class=&#34;n&#34;&gt;critical_value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_sim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       &lt;span class=&#34;n&#34;&gt;SESOI&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;estim_fix_effs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0.85&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;power_mixed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;multiplotPower&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;power_mixed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# End of script&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;################################################################################&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Happy R&amp;rsquo;ing!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...write a paper</title>
      <link>https://hrbosker.github.io/resources/how-to/write-a-manuscript/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/write-a-manuscript/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Here&amp;rsquo;s a Word template that includes all basic sections of a paper, template statements (e.g., ethics, participants specs, etc.), &amp;lsquo;fields&amp;rsquo; to automatically update figure/table numbers, heading styles, and Zotero for reference management.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;word-template&#34;&gt;Word template&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Download the &lt;a href=&#34;manuscript-template.docx&#34;&gt;Word template&lt;/a&gt; here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;tips-n-tricks&#34;&gt;Tips n tricks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start now.&lt;/strong&gt; In the olden days, I wrote the paper after all experiments had been run, all data had been collected and analyzed, and I had made my mind up about its theoretical implications. Don&amp;rsquo;t go there! &lt;em&gt;Start writing the moment you think of your research question.&lt;/em&gt; Take the template above and just start filling in some of the gaps with text. Add a Methods section when you&amp;rsquo;ve designed the experiment, start adding some sentences to the Introduction when waiting for data to come in, add a reference immediately the moment you encounter a paper you will definitely want to cite, you can even start writing the Results and General Discussion based on your expectations, and then once the data are in, all you need to do is just fill in the numbers. It takes some commitment and diligence, but it will pay off in the end!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cut an onion.&lt;/strong&gt; A paper is like an onion: start BIG AND GRAND at the beginning, describing a major problem in human behavior, and then gradually get smaller and smaller and more detailed as you reach the end of the Introduction, describing the actual experiment, then go really nitty-gritty when you reach the Methods and Results. When you reach the General Discussion, you start zooming out again, first summarizing the experimental outcomes, then discussing their theoretical implications, and finally drawing BIG AND GRAND conclusions about life, the universe, and everything.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Build a skeleton.&lt;/strong&gt; First try to create an outline of your Introduction, using one sentence to summarize each paragraph. Start with &amp;ldquo;Speech perception is amazing&amp;rdquo; for the first paragraph, and &amp;ldquo;This experiment tested&amp;hellip;&amp;rdquo; for the final paragraph of the Introduction, and try to find your way from the first claim to the last one. For instance:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(1)&lt;/strong&gt; &lt;em&gt;Speech perception is amazing&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(2)&lt;/strong&gt; &lt;em&gt;People use both visual and auditory cues in speech perception&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(3)&lt;/strong&gt; &lt;em&gt;These visual cues include both facial articulatory cues as well as hand gestures&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(4)&lt;/strong&gt; &lt;em&gt;However, little is known about how visual cues to prosody influence speech perception&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(5)&lt;/strong&gt; &lt;em&gt;Therefore, this experiment tested&amp;hellip;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once you have this skeleton, all you then need to do is just &amp;lsquo;fill the paragraphs with words&amp;rsquo;. The skeleton also helps to find out which citation goes where (as in: when should I cite this seminal study I found?). Finally, according to the Onion Theory, the General Discussion is then simply the skeleton for the Introduction turned upside down:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(5)&lt;/strong&gt; &lt;em&gt;This experiment tested ABC and found XYZ&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(4)&lt;/strong&gt; &lt;em&gt;This suggests that people use visual gestural cues to prosody in speech perception&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(3)&lt;/strong&gt; &lt;em&gt;How these visual cues interact with other visual cues, such as articulation on the face, remains an issue for future research&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(2)&lt;/strong&gt; &lt;em&gt;Our outcomes emphasize the importance of both visual and auditory cues in face-to-face spoken communication.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;(1)&lt;/strong&gt; &lt;em&gt;Isn&amp;rsquo;t speech perception amazing?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cheat.&lt;/strong&gt; Use tools such as Thesaurus for synonym searching, Zotero for reference management, fields in Word for figure and table numbers, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Now just start typing.&lt;/strong&gt; It&amp;rsquo;s easier to revise and edit something that you wrote yesterday than to fill an empty page. So why not jot down a few sketchy sentences and rework them later into something nice?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;em&gt;Did you know that&amp;hellip;&lt;/em&gt; in the olden days, &lt;a href=&#34;https://apastyle.apa.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;APA guidelines&lt;/a&gt; asked you to place figures only at the end of the manuscript, presumably for copyediting reasons. Their positions in the main text were identified by short &amp;ldquo;Insert Figure 1 about here&amp;rdquo; boxes. However, this is a real pain, for reviewers in particular (and everyone else too, really&amp;hellip;), because this means you need to flip back and forth between main text and figures to understand the results. It&amp;rsquo;s much easier and more effective if you place figures in text. Even if journal guidelines still ask you to place figures at the end of the manuscript, I usually just put them in text and wait for an editorial assistant to call me out&amp;hellip;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Happy writing!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...submit a manuscript</title>
      <link>https://hrbosker.github.io/resources/how-to/submit-a-manuscript/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/submit-a-manuscript/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This describes which journal to choose, which suggested (or dispreferred?) reviewers to mention, what should go into a cover letter, how to read the submission system,  and when to contact the editorial office about your submission.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    I currently serve as Associate Editor of the journal &lt;em&gt;Language &amp;amp; Speech&lt;/em&gt;. However, the statements below do not reflect the official opinion of &lt;em&gt;Language &amp;amp; Speech&lt;/em&gt; nor any other journal I ever edited or reviewed for. They merely describe my personal experiences with submitting, reviewing, and editing papers, so take them with a grain of salt&amp;hellip;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;what-journal-do-i-pick&#34;&gt;What journal do I pick?&lt;/h2&gt;
&lt;p&gt;Nowadays, with Twitter, Psyarxiv, and Google Scholar, what journal a paper appears in has become a lot less important. Your peers will see it online no matter where it is published. Moreover, science as a whole is moving towards valuing the impact of an article on its own merits rather than weighing its value by the impact factor of the journal it appeared in. Still, in general, one can say that the broader the interest and audience of the journal, the more prestigious it is considered, and the harder it is to get a paper accepted (think &lt;em&gt;Nature&lt;/em&gt; vs. &lt;em&gt;Language and Speech&lt;/em&gt;, for instance). That said, the story is a little different for open access journals of broad interest. Even though these journals have papers from a wide range of disciplines, it is - at least in my experience - easier to get into these than their non-open broad-interest counterparts, hurting their prestige a bit.&lt;/p&gt;
&lt;p&gt;As speech researchers, we are livin&amp;rsquo; on the edge&amp;hellip; of the fields of experimental psychology, neurobiology, and the speech sciences. Consequently, we need to consider journals from differents fields. Is your experimental study more appealing and relevant to a psychology crowd, or to hardcore phoneticians, or nutty neuroscientists? Also remember there is no single perfect journal for your study; in fact, in all likelihood you may have to go through several before seeing it in print. Here are some things to consider&amp;hellip;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider a journal&amp;rsquo;s prestige because that will influence your chances of getting in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider the journal&amp;rsquo;s values, for instance in terms of open access and open data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider the implications of your study: some papers simply fit better in a specialist journal than in one of broad interest.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider your CV: it&amp;rsquo;s probably better if your CV lists publications in different journals from different fields compared to only publishing in a single specialist journal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider journal-specific criteria and guidelines, such as what article types do they have (Regular Article vs. Brief Reports), what word limits do they have, etc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Finally, &lt;em&gt;before submitting&lt;/em&gt; check &lt;strong&gt;whether your institution has an agreement with the target journal about open access fees&lt;/strong&gt;. Many academic institutions will have signed contracts with publishers, waiving open access fees for their employees. However, often certain conditions apply, such as applying only to first-authors, or to authors with an institute email address. Make sure you know about these conditions before submitting as whatever details you submit will decide whether or not your paper falls under those institutional agreements.&lt;/p&gt;
&lt;h2 id=&#34;submitting-your-paper&#34;&gt;Submitting your paper&lt;/h2&gt;
&lt;p&gt;Most journals work with an online submission system, such as &lt;em&gt;Manuscript Central&lt;/em&gt;. Go to the website of your journal of interest, search for &amp;lsquo;Submit your paper here&amp;rsquo; or something similar, and create an account with the system.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    It helps if you create your account carefully because many of your account&amp;rsquo;s details will carry over to your submissions. For instance, &lt;strong&gt;add your ORCID number&lt;/strong&gt; to your account so your ORCID iD will automatically appear on your publications. &lt;strong&gt;Use your institute email address&lt;/strong&gt; so your institute will pay the open access fees.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Then create a new submission, which typically involves&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;selecting an article type&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Is this a Regular Article (most experimental studies are) or a Review Paper (without new empirical data)? Or is it a Brief Report (check out the journal guidelines) or even a Registered Report (pre-registered study in an open repository, like OSF)?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;copying some manuscript details&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Copy the title, abstract, keywords, etc. into the relevant boxes. Note that most submission systems are simple text only, so formatting in the title or abstract may get lost. Make sure you enter these details only when the manuscript is in its definitive form. You don&amp;rsquo;t want to have a different title in the system vs. in the manuscript itself. This is particularly relevant for &lt;strong&gt;keywords&lt;/strong&gt;. Some journals allow you to select keywords yourself (see journal guidelines for how many and what character to use to separate different keywords) but sometimes they ask you to select from a dropdown menu. If the latter, you want to make sure you don&amp;rsquo;t have different keywords in the manuscript.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;ticking a few boxes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;No, we did not submit this paper anywhere else; yes, we adhered to all relevant ethical requirements and guidelines; no, we do not have any conflicts of interest.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;uploading all relevant files&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Upload your manuscript (.docx), any supplementary information (.pdf), raw figure files (.eps or .pdf), and a cover letter (.pdf). Check with the journal what file format to use. If possible, use vector-based formats like .eps and .pdf for figures because they look nicer in print. However, because Word doesn&amp;rsquo;t like these formats, I do use .png or .jpg images inside the manuscript&amp;rsquo;s Word document. Cover letters are stemming from the olden days when they were used to include &amp;rsquo;not published elsewhere&amp;rsquo;-statements, author contact details, etc., but nowadays these details live inside the submission system. Still, it&amp;rsquo;s nice to have one, especially to highlight the importance, novelty, and main take-away messages from the paper. For broad-interest journals with lots of desk rejections, the cover letter is important; you&amp;rsquo;ll really need to sell your study.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Download a &lt;a href=&#34;cover-letter-template.docx&#34;&gt;cover letter template&lt;/a&gt; here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Sometimes journals ask you to upload a &amp;ldquo;PDF for reviewers&amp;rdquo;. This is identical to the main manuscript, except that it is in .pdf format and has all figures and tables in the text. In the olden days, &lt;a href=&#34;https://apastyle.apa.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;APA guidelines&lt;/a&gt; asked you to place figures only at the end of the manuscript, presumably for copyediting reasons. Their positions in the main text were then identified by the authors by including short &amp;ldquo;Insert Figure 1 about here&amp;rdquo; boxes. However, this is a real pain for readers, and reviewers in particular (and everyone else too, really&amp;hellip;), because this means you need to flip back and forth between main text and figures to understand the results. It&amp;rsquo;s much easier and more effective if you place figures in text. Even if journal guidelines still ask you to place figures at the end of the manuscript, I usually just put them in text anyway and wait for an editorial assistant to call me out&amp;hellip;
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;adding suggested reviewers&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes this is mandatory, sometimes this is optional. If optional, it&amp;rsquo;s fine to leave it open but it can help speed up the review process. It is not uncommon for editors to have to invite &amp;gt;20 reviewers before finally finding two who accept, so giving the editor a hand doesn&amp;rsquo;t hurt. &lt;strong&gt;How to select them?&lt;/strong&gt; Often these are people whose work you cite in the paper. However, it&amp;rsquo;s probably better not to go for the big fish, as these people typically already receive many review requests and are more likely to decline. Why not consider selecting a postdoc from their lab? Why not consider diversity and gender balance in your suggested reviewers? Note, by the way, that it is uncommon to suggest reviewers who have not yet obtained a PhD. Also do not suggest researchers you&amp;rsquo;ve worked with in the past.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Some editorial boards are critical of suggested reviewers because of scams in the past. There have been cases when authors created fake online profiles of &amp;ldquo;Dr. A.B.C. Smith&amp;rdquo;, linked &lt;a href=&#34;mailto:abcsmith@university.com&#34;&gt;abcsmith@university.com&lt;/a&gt; to their own email inbox, and then suggested Dr. Smith as a possible reviewer, &amp;hellip; well, you get the idea. Nevertheless, it doesn&amp;rsquo;t hurt to provide a few suggestions (unless explicitly asked not to, of course); it&amp;rsquo;s the editor&amp;rsquo;s job to simply be careful in their review invitations.
  &lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;add dispreferred reviewers&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is optional; they&amp;rsquo;re left empty in most cases. I have never filled these out myself and honestly I do not even know how most editors will use this information. Will they invite them anyway to get a different perspective on the paper, or will they honor the authors&amp;rsquo; request not to invite them? Even if you have a name in mind for this category, I guess you can still leave this box empty because chances are slim that the editor will specifically invite that person anyway.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;hellip;clicking [SUBMIT]!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Fingers crossed! Wait at least 3 months before contacting the editorial office about any updates (don&amp;rsquo;t use the editor&amp;rsquo;s personal email address). Be curteous and kindly ask whether they can inform you about your manuscript&amp;rsquo;s current status. They&amp;rsquo;ll likely inform you that they&amp;rsquo;re waiting for one reviewer to get back to them, and if you&amp;rsquo;re lucky they may give you an indication of when they expect all reviews to be in. The submission system itself usually also tells you what the status of your submission is, but these labels (like &amp;ldquo;With Editor&amp;rdquo;, &amp;ldquo;Under Review&amp;rdquo;, &amp;ldquo;Waiting for Editorial Decision&amp;rdquo;) usually do not tell you very much. Your paper can be &amp;ldquo;Under Review&amp;rdquo; the moment the first reviewer accepts, but then the editor may have considerable trouble finding the second one, who knows&amp;hellip;?!?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Happy submitting!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>...reply to reviews</title>
      <link>https://hrbosker.github.io/resources/how-to/reply-to-reviews/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hrbosker.github.io/resources/how-to/reply-to-reviews/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This talks about when to open that email that contains your fresh reviews, how to weigh the reviewers&amp;rsquo; feedback, how to respond, and how best to structure your response file.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    I currently serve as Associate Editor of the journal &lt;em&gt;Language &amp;amp; Speech&lt;/em&gt;. However, the statements below do not reflect the official opinion of &lt;em&gt;Language &amp;amp; Speech&lt;/em&gt; nor any other journal I ever edited or reviewed for. They merely describe my personal experiences with submitting, reviewing, and editing papers, so take them with a grain of salt&amp;hellip;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;reviews-are-in-now-what&#34;&gt;Reviews are in! Now what?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;It&amp;rsquo;s a random Friday afternoon, you&amp;rsquo;re just about to close your laptop for the weekend, when you see this email appear in your inbox, with the obscure subject &amp;ldquo;Decision on XYZ-01234&amp;rdquo;. &lt;strong&gt;What do you do?&lt;/strong&gt; Do you open it immediately, do you leave it be for the weekend, do you forward it to your supervisors without opening?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I probably have never read a decision letter and felt delighted afterwards. Here&amp;rsquo;s a project you&amp;rsquo;ve spent years of your time on and now these anonymous strangers get to shoot at it! Do you really want the reviews to spoil your weekend? Why not leave it for now and book a timeslot in your agenda to carefully read it in full?&lt;/p&gt;
&lt;p&gt;After the first read, it can really take some mental effort to take a deep breath and think about the reviews in a constructive manner. It may help to ask your supervisors and/or co-authors &amp;ndash; who may have had the pleasure of receiving reviews more often than you have &amp;ndash; for their opinions and perspectives. Forward the entire decision letter to them asap and schedule a meeting to go through it together, and in the meanwhile let the general impression sink in. Take some distance, there&amp;rsquo;s no real rush; leave it be for a while, take a few days to consider different perspectives. Keep in mind that &amp;lsquo;major revisions&amp;rsquo; does not mean &amp;rsquo;this study has major flaws&amp;rsquo; but is in practice the standard status of any manuscript sent back for revisions. In fact, in my (by now 12-year-long) academic career, I&amp;rsquo;ve received a &amp;lsquo;minor revisions&amp;rsquo; decision only once. All in all, this may help to avoid becoming grumpy and defensive, to put things into perspective, and adopt a constructive mindset.&lt;/p&gt;
&lt;h2 id=&#34;how-to-respond&#34;&gt;How to respond?&lt;/h2&gt;
&lt;p&gt;Well, on a practical level, copy the entire decision letter into a new document. Then paste &lt;strong&gt;***RESPONSE #1***&lt;/strong&gt; beneath the first comment, &lt;strong&gt;***RESPONSE #2***&lt;/strong&gt; below the second, etc. Then go through the document and write down how you&amp;rsquo;d like to respond to individual comments. This can be really informal at first (&lt;em&gt;&amp;ldquo;Need to look up refs&amp;rdquo;&lt;/em&gt;) but it helps to get an idea of how much work needs to be done. Also create a copy of the original manuscript, rename it, and start Track Changes to keep track of what&amp;rsquo;s been changed (useful for you and useful for co-authors).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips n tricks:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number your responses. This makes it easier to refer back to points already addressed earlier. Do not respond &amp;ldquo;Please see our earlier response above&amp;rdquo; but be specific: &amp;ldquo;Please see our Response #9&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Use &amp;lsquo;fields&amp;rsquo; in Word. Instead of manually typing from 1 to 134, copy the same statement including a field below each comment, and hit CTRL-A and then F9 to automatically update the fields.&lt;/li&gt;
&lt;li&gt;Use a different font or color for your responses so it is immediately clear what was the original comment and what is your response. Note however that some journals do not allow you to upload a &amp;lsquo;Response to reviewers&amp;rsquo; document but instead ask you to copy your responses into a plain text box. This will remove any formatting, so also use *** or ### to mark your responses.&lt;/li&gt;
&lt;li&gt;Look up a paper in a journal with open reviews (e.g., recent papers in &lt;em&gt;eLife, Royal Society Open Science, Nature Communications&lt;/em&gt;). You&amp;rsquo;ll be able to see how others have dealt with critical comments and still managed to get their paper published!&lt;/li&gt;
&lt;li&gt;Make your reviewers&amp;rsquo; life easy: add page numbers to every response that involved changes in the manuscript. Tip: initially use something easily findable, like &lt;code&gt;#pagenumber&lt;/code&gt;, and only replace these with the actual page numbers at the very end, right before you resubmit.&lt;/li&gt;
&lt;li&gt;Also: keep it snappy. Don&amp;rsquo;t respond to single-line comments with pages-and-pages of words. Also don&amp;rsquo;t spend too many words thanking reviewers at the beginning of each and every response. Instead, keep it efficient. Jump straight into the issue without further ado. Reviewers, when receiving your rebuttal, will want to know how you handled their questions and critiques; they don&amp;rsquo;t want to have to wade through lines and lines of (sometimes feigned) gratitude.&lt;/li&gt;
&lt;li&gt;Your responses to substantial comments are best also included (likely in a trimmed down version) in the manuscript. Remember that, for most journals, the reviews aren&amp;rsquo;t open. This means that the points raised by the reviewers and your responses to them aren&amp;rsquo;t accessible to other readers. Still, they may have the same questions or concerns as your reviewers. Therefore, aim for an accurate and complete published record in which you explicitly acknowledge critical perspectives (&amp;ldquo;An anonymous reviewer mentioned that&amp;hellip;&amp;rdquo;) and your responses to them (&amp;ldquo;However, we should point out that&amp;hellip;&amp;rdquo;).&lt;/li&gt;
&lt;li&gt;Give your reviewers the benefit of the doubt. This can be particularly challenging when you disagree with reviewer suggestions. Try to see the whole reviewing entreprise as something collaborative (&lt;em&gt;&amp;hellip;we&amp;rsquo;re all in this together to make it the best possible paper&lt;/em&gt;) instead of something competitive (&lt;em&gt;&amp;hellip;how can we make the author&amp;rsquo;s life as difficult as possible?&lt;/em&gt;). These annoying and troublesome strangers actually voluntarily invested a few hours if not days reading and thinking about your paper. Imagine them receiving your responses after several months have gone by, not exactly remembering what was wrong with the manuscript and why, only to find that the authors have dismissed their feedback with a few simple sentences. This would annoy even the most constructive of reviewers. Take the feedback seriously and show you&amp;rsquo;ve given their comments considerable thought.&lt;/li&gt;
&lt;li&gt;In the unlikely event you receive comments that are disrespectful, don&amp;rsquo;t respond in the same tone of voice. Be polite, courteous, and constructive; that way you will likely change the tone of the discussion. At the same time, you demonstrate to the editor &amp;ndash; who in the end is the one who makes the final decision on your submission &amp;ndash; that you have considered the criticism seriously and have responded in a mature manner, winning them over to your side.&lt;/li&gt;
&lt;li&gt;In the likely event you receive particularly useful and insightful comments, do feel free to explicitly express your gratitude (e.g., &amp;ldquo;We found this comment particularly insightful because XYZ&amp;rdquo;). However, don&amp;rsquo;t overdo it. Only include a handful of these thank-you-notes and why not try to distribute them equally across all reviewers, not to upset anyone&amp;hellip;&lt;/li&gt;
&lt;li&gt;If after reading and re-reading and discussing the reviews with your co-authors, some comment remains unclear to you, do get in touch with the editor to ask for clarification. &lt;strong&gt;Do not ask&lt;/strong&gt; &amp;ldquo;if we only do ABC and not XYZ, will you then accept our paper?&amp;rdquo;. Rather, &amp;ldquo;we do not fully understand this comment about ABC because XYZ. Could you please clarify what criticism this comment raises?&amp;rdquo;. Do not get in touch with reviewers directly if you know their identity.&lt;/li&gt;
&lt;li&gt;Finally, if your paper is reviewed but rejected by the editor, do revise your manuscript before sending it out to another journal. Don&amp;rsquo;t simply send out the old manuscript to a new journal; it could be the new journal happens to invite (some of) the same reviewers as before. But even if they don&amp;rsquo;t, the initial reviewers may see the paper out in print in another journal some day, still including some of the same mistakes or misinterpretations they pointed out initially. Again, take their comments seriously, revise, and then resubmit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Happy rebutting!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
